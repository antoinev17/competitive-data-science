{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "* Step 1: prepare the training and evaluation data set\n",
    "* Step 2: training with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import calendar\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_extraction\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "\n",
    "# To use part or all the train set\n",
    "training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load all Files (hey must be in input directory in a brother directory of the notebook)\n",
    "data_load = {\n",
    "    'item_categories': pd.read_csv('../input/item_categories.csv'), \n",
    "    'items': pd.read_csv('../input/items.csv'), \n",
    "    'sales_train': pd.read_csv('../input/sales_train_v2.csv'),\n",
    "    'sample_submission': pd.read_csv('../input/sample_submission.csv'),\n",
    "    'shops': pd.read_csv('../input/shops.csv'),\n",
    "    'test': pd.read_csv('../input/test.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = {}\n",
    "\n",
    "# Sales data \n",
    "data_load['sales_train']['date'] = pd.to_datetime(data_load['sales_train']['date'], format = \"%d.%m.%Y\")\n",
    "\n",
    "#Data['sales']['day'] = transactions['date'].dt.day\n",
    "data_load['sales_train']['month'] = data_load['sales_train']['date'].dt.month\n",
    "data_load['sales_train']['year'] = data_load['sales_train']['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>669316</th>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669317</th>\n",
       "      <td>2013-07-25</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827143</th>\n",
       "      <td>2013-08-05</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877001</th>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401436</th>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  date_block_num  shop_id  item_id  item_price  \\\n",
       "669316  2013-07-23               6        5      485       300.0   \n",
       "669317  2013-07-25               6        5      485       300.0   \n",
       "827143  2013-08-05               7        5      485       300.0   \n",
       "877001  2013-09-07               8        5      485       300.0   \n",
       "1401436 2014-02-28              13        5      485       300.0   \n",
       "\n",
       "         item_cnt_day  month  year  \n",
       "669316            1.0      7  2013  \n",
       "669317            1.0      7  2013  \n",
       "827143            1.0      8  2013  \n",
       "877001            1.0      9  2013  \n",
       "1401436           1.0      2  2014  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_load['sales_train'][(data_load['sales_train'].shop_id == 5) & (data_load['sales_train'].item_id == 485)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2935849</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2013-12-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2015-10-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.456991e+01</td>\n",
       "      <td>3.300173e+01</td>\n",
       "      <td>1.019723e+04</td>\n",
       "      <td>8.908532e+02</td>\n",
       "      <td>1.242641e+00</td>\n",
       "      <td>6.247717e+00</td>\n",
       "      <td>2.013777e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.422988e+00</td>\n",
       "      <td>1.622697e+01</td>\n",
       "      <td>6.324297e+03</td>\n",
       "      <td>1.729800e+03</td>\n",
       "      <td>2.618834e+00</td>\n",
       "      <td>3.536219e+00</td>\n",
       "      <td>7.684790e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-2.200000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>4.476000e+03</td>\n",
       "      <td>2.490000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>9.343000e+03</td>\n",
       "      <td>3.990000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.014000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>1.568400e+04</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.014000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>2.216900e+04</td>\n",
       "      <td>3.079800e+05</td>\n",
       "      <td>2.169000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  date_block_num       shop_id       item_id  \\\n",
       "count               2935849    2.935849e+06  2.935849e+06  2.935849e+06   \n",
       "unique                 1034             NaN           NaN           NaN   \n",
       "top     2013-12-28 00:00:00             NaN           NaN           NaN   \n",
       "freq                   9434             NaN           NaN           NaN   \n",
       "first   2013-01-01 00:00:00             NaN           NaN           NaN   \n",
       "last    2015-10-31 00:00:00             NaN           NaN           NaN   \n",
       "mean                    NaN    1.456991e+01  3.300173e+01  1.019723e+04   \n",
       "std                     NaN    9.422988e+00  1.622697e+01  6.324297e+03   \n",
       "min                     NaN    0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%                     NaN    7.000000e+00  2.200000e+01  4.476000e+03   \n",
       "50%                     NaN    1.400000e+01  3.100000e+01  9.343000e+03   \n",
       "75%                     NaN    2.300000e+01  4.700000e+01  1.568400e+04   \n",
       "max                     NaN    3.300000e+01  5.900000e+01  2.216900e+04   \n",
       "\n",
       "          item_price  item_cnt_day         month          year  \n",
       "count   2.935849e+06  2.935849e+06  2.935849e+06  2.935849e+06  \n",
       "unique           NaN           NaN           NaN           NaN  \n",
       "top              NaN           NaN           NaN           NaN  \n",
       "freq             NaN           NaN           NaN           NaN  \n",
       "first            NaN           NaN           NaN           NaN  \n",
       "last             NaN           NaN           NaN           NaN  \n",
       "mean    8.908532e+02  1.242641e+00  6.247717e+00  2.013777e+03  \n",
       "std     1.729800e+03  2.618834e+00  3.536219e+00  7.684790e-01  \n",
       "min    -1.000000e+00 -2.200000e+01  1.000000e+00  2.013000e+03  \n",
       "25%     2.490000e+02  1.000000e+00  3.000000e+00  2.013000e+03  \n",
       "50%     3.990000e+02  1.000000e+00  6.000000e+00  2.014000e+03  \n",
       "75%     9.990000e+02  1.000000e+00  9.000000e+00  2.014000e+03  \n",
       "max     3.079800e+05  2.169000e+03  1.200000e+01  2.015000e+03  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_load['sales_train'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training/evaluation set, with similar pattern as the test set:\n",
    "* All shops in both sets\n",
    "* evaluation set on the last month\n",
    "* unknown items in the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Calculate the total of items sold per month, item, shop\n",
    "\n",
    "Data['train'] = data_load['sales_train'].groupby(['date_block_num', 'shop_id', 'item_id'], as_index = False).item_cnt_day.agg({\n",
    "    'item_cnt_month': np.sum\n",
    "})\n",
    "\n",
    "# We calculate the average per line, not weighted by the number of sales to simplify (and avoid division per 0)\n",
    "\n",
    "tmp = data_load['sales_train'].groupby(['date_block_num', 'shop_id', 'item_id'], as_index= False).item_price.agg({\n",
    "    'item_mean_price_shop_month': np.mean\n",
    "})\n",
    "\n",
    "Data['train'] = Data['train'].merge(tmp,\n",
    "                    how = 'left',\n",
    "                    on = ['date_block_num', 'shop_id', 'item_id'])\n",
    "\n",
    "if training: \n",
    "    \n",
    "    # Split on date\n",
    "    \n",
    "    condition = Data['train']['date_block_num']==33\n",
    "    Data['evaluation'] = Data['train'][condition]\n",
    "    Data['train'] = Data['train'][~condition]\n",
    "    \n",
    "    print(\"sizes:\" ,Data['evaluation'].shape, Data['train'].shape)\n",
    "\n",
    "    # The following part was disable, because the evaluation set already presents a larger proportion of unknown items than \n",
    "    # the test set\n",
    "    \n",
    "    # Select 7.1% of the items to remove from the data set (363 on 5100 )\n",
    "    # This may be too high, as some items could be appearing only in this last month: TO CHECK > in fact the proportion \n",
    "    # of missing item is already too large\n",
    "\n",
    "    #list_item_ids = list(Data['train'].item_id.unique())\n",
    "    #n = int(363/5100*21807)\n",
    "\n",
    "    # Remove the items from training set\n",
    "\n",
    "    #removed_item_ids = random.sample(list_item_ids, n)\n",
    "    #print(\"Number of items removed from train set:\", len(removed_item_ids))\n",
    "\n",
    "    #condition = Data['train'].item_id.isin(removed_item_ids)\n",
    "    #Data['train'] = Data['train'][~condition]\n",
    "\n",
    "    #print(Data['evaluation'].shape, Data['train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_mean_price_shop_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353061</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411402</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468936</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742695</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_block_num  shop_id  item_id  item_cnt_month  \\\n",
       "353061               6        5      485             2.0   \n",
       "411402               7        5      485             1.0   \n",
       "468936               8        5      485             1.0   \n",
       "742695              13        5      485             1.0   \n",
       "\n",
       "        item_mean_price_shop_month  \n",
       "353061                       300.0  \n",
       "411402                       300.0  \n",
       "468936                       300.0  \n",
       "742695                       300.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Data['train'][( Data['train'].shop_id == 5) & ( Data['train'].item_id == 485)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winsorization - on training set only to evaluate the effect on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_limit = Data['train'].item_mean_price_shop_month.quantile([0.0, 0.999])[0.999]\n",
    "prices = Data['train'].item_mean_price_shop_month\n",
    "Data['train'].loc[(prices > price_limit), 'item_mean_price_shop_month'] = price_limit\n",
    "\n",
    "# clipping must be done after the stats are calculated\n",
    "#Data['train'].loc[:,'item_cnt_month'] = Data['train'].item_cnt_month.clip(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the missing rows for train set...\n"
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    set_list = ['train', 'evaluation']\n",
    "else:\n",
    "    set_list = ['train']\n",
    "    \n",
    "months = data_load['sales_train'].groupby(['month', 'year'], as_index = False).date_block_num.first()\n",
    "\n",
    "for set_name in set_list:\n",
    "\n",
    "    # Add the missing rows date_block_num,shop_id, item_id with item_cnt_month = 0\n",
    "    \n",
    "    print('Adding the missing rows for', set_name, 'set...')\n",
    "    unique_date_block_num = sorted(Data[set_name].date_block_num.unique())\n",
    "    unique_shop_id = sorted(Data[set_name].shop_id.unique())\n",
    "    unique_item_id = sorted(Data[set_name].item_id.unique())\n",
    "\n",
    "    d = {\n",
    "        'date_block_num': unique_date_block_num,\n",
    "        'item_id': unique_item_id,\n",
    "        'shop_id': unique_shop_id\n",
    "    }\n",
    "\n",
    "    tmp = list(itertools.product(*[unique_date_block_num, unique_item_id, unique_shop_id]))\n",
    "    od = OrderedDict(sorted(d.items()))\n",
    "\n",
    "    df = pd.DataFrame(tmp,columns=od.keys())\n",
    "    Data[set_name] = df.merge(Data[set_name],\n",
    "                             how= 'left',\n",
    "                             on = ['shop_id', 'item_id', 'date_block_num'])\n",
    "\n",
    "    # Add the month and year\n",
    "    \n",
    "    Data[set_name] = Data[set_name].merge(months,\n",
    "                   how = 'left',\n",
    "                   on = ['date_block_num'])\n",
    "    \n",
    "    # For new rows missing values:\n",
    "    \n",
    "    Data[set_name].item_cnt_month = Data[set_name].item_cnt_month.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_mean_price_shop_month</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.448628e+07</td>\n",
       "      <td>4.448628e+07</td>\n",
       "      <td>4.448628e+07</td>\n",
       "      <td>4.448628e+07</td>\n",
       "      <td>1.609124e+06</td>\n",
       "      <td>4.448628e+07</td>\n",
       "      <td>4.448628e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.650000e+01</td>\n",
       "      <td>1.109870e+04</td>\n",
       "      <td>2.950000e+01</td>\n",
       "      <td>8.200744e-02</td>\n",
       "      <td>7.867442e+02</td>\n",
       "      <td>6.205882e+00</td>\n",
       "      <td>2.013941e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.810709e+00</td>\n",
       "      <td>6.396913e+03</td>\n",
       "      <td>1.731810e+01</td>\n",
       "      <td>1.698690e+00</td>\n",
       "      <td>1.466117e+03</td>\n",
       "      <td>3.323529e+00</td>\n",
       "      <td>8.022460e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.200000e+01</td>\n",
       "      <td>9.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>5.551000e+03</td>\n",
       "      <td>1.475000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.650000e+01</td>\n",
       "      <td>1.110500e+04</td>\n",
       "      <td>2.950000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.990000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.014000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.664800e+04</td>\n",
       "      <td>4.425000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.985000e+02</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>2.216900e+04</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>2.253000e+03</td>\n",
       "      <td>2.269199e+04</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_block_num       item_id       shop_id  item_cnt_month  \\\n",
       "count    4.448628e+07  4.448628e+07  4.448628e+07    4.448628e+07   \n",
       "mean     1.650000e+01  1.109870e+04  2.950000e+01    8.200744e-02   \n",
       "std      9.810709e+00  6.396913e+03  1.731810e+01    1.698690e+00   \n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00   -2.200000e+01   \n",
       "25%      8.000000e+00  5.551000e+03  1.475000e+01    0.000000e+00   \n",
       "50%      1.650000e+01  1.110500e+04  2.950000e+01    0.000000e+00   \n",
       "75%      2.500000e+01  1.664800e+04  4.425000e+01    0.000000e+00   \n",
       "max      3.300000e+01  2.216900e+04  5.900000e+01    2.253000e+03   \n",
       "\n",
       "       item_mean_price_shop_month         month          year  \n",
       "count                1.609124e+06  4.448628e+07  4.448628e+07  \n",
       "mean                 7.867442e+02  6.205882e+00  2.013941e+03  \n",
       "std                  1.466117e+03  3.323529e+00  8.022460e-01  \n",
       "min                  9.000000e-02  1.000000e+00  2.013000e+03  \n",
       "25%                  1.990000e+02  3.000000e+00  2.013000e+03  \n",
       "50%                  3.990000e+02  6.000000e+00  2.014000e+03  \n",
       "75%                  8.985000e+02  9.000000e+00  2.015000e+03  \n",
       "max                  2.269199e+04  1.200000e+01  2.015000e+03  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['train'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the test set\n",
      "Adding item category stats\n",
      "Adding item count lagged values\n",
      "Test set - Calculating lag: 1\n",
      "Test set - Calculating lag: 3\n",
      "Test set - Calculating lag: 12\n",
      "Adding item count stats\n",
      "Adding shop item price stats\n",
      "Adding overall item price stats\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 'train' must be first in those lists\n",
    "if training:\n",
    "    set_list = ['train','evaluation']\n",
    "else:\n",
    "    set_list = ['train', 'test']\n",
    "\n",
    "if ~training:\n",
    "    # Prepare the test set\n",
    "    print(\"Preparing the test set\")\n",
    "\n",
    "    Data['test'] = data_load['test'].copy()\n",
    "    Data['test']['month'] = 11\n",
    "    Data['test']['year'] = 2015\n",
    "    Data['test']['date_block_num'] = 34\n",
    "\n",
    "    cols = ['ID', 'date_block_num', 'item_id', 'shop_id','month', 'year']\n",
    "    Data['test'] = Data['test'][cols]\n",
    "\n",
    "#print(Data['test'].columns.tolist())\n",
    "\n",
    "### Add the item_category\n",
    "\n",
    "print(\"Adding item category stats\")\n",
    "\n",
    "for set_name in set_list:\n",
    "    Data[set_name] = Data[set_name].merge(data_load['items'],\n",
    "            how = 'left',\n",
    "            on = 'item_id',\n",
    "            ).drop(['item_name'], axis = 1)\n",
    "\n",
    "# Stats over the items and the months\n",
    "tmp = Data['train'].groupby(['shop_id', 'item_category_id'], as_index = False).item_cnt_month.agg({\n",
    "    'category_cnt_month_mean': np.mean,   \n",
    "    'category_cnt_month_max': np.max\n",
    "})\n",
    "\n",
    "for set_name in set_list:\n",
    "    Data[set_name] = Data[set_name].merge(tmp,\n",
    "            how = 'left',\n",
    "            on = ['item_category_id', 'shop_id']\n",
    "            )\n",
    "    \n",
    "# The category without sales for this restaurant will remain with a NaN (removed when creating the X/y)\n",
    "\n",
    "### Add the lagged information on item count\n",
    "print(\"Adding item count lagged values\")\n",
    "\n",
    "Data['train']['item_cnt_month_minus_12'] = 0\n",
    "Data['train']['item_cnt_month_minus_3'] = 0\n",
    "Data['train']['item_cnt_month_minus_1'] = 0 \n",
    "\n",
    "for it_month in range(12, 33,1):\n",
    "    condition = Data['train'].date_block_num == it_month\n",
    "    Data['train'].loc[condition, 'item_cnt_month_minus_12'] = Data['train'][(Data['train'].date_block_num == it_month-12)]\\\n",
    "        .as_matrix(columns=['item_cnt_month'])    \n",
    "    Data['train'].loc[condition, 'item_cnt_month_minus_3'] = Data['train'][(Data['train'].date_block_num == it_month-3)]\\\n",
    "        .as_matrix(columns=['item_cnt_month'])\n",
    "    Data['train'].loc[condition, 'item_cnt_month_minus_1'] = Data['train'][(Data['train'].date_block_num == it_month-1)]\\\n",
    "        .as_matrix(columns=['item_cnt_month'])\n",
    "\n",
    "if training:\n",
    "    for lag in [1,3,12]:\n",
    "        print(\"Evaluation set - Calculating lag:\",lag)\n",
    "        tmp = Data['train'][Data['train'].date_block_num == (33-lag)][['item_id', 'shop_id','item_cnt_month']]\\\n",
    "            .rename(columns={'item_cnt_month':'item_cnt_month_minus_'+str(lag) })\n",
    "        Data['evaluation'] = Data['evaluation'].merge(tmp,\n",
    "                how = 'left',\n",
    "                on = ['item_id', 'shop_id']\n",
    "                )    \n",
    "else:     \n",
    "    for lag in [1,3,12]:\n",
    "        print(\"Test set - Calculating lag:\",lag)\n",
    "        tmp = Data['train'][Data['train'].date_block_num == (34-lag)][['item_id', 'shop_id','item_cnt_month']]\\\n",
    "            .rename(columns={'item_cnt_month':'item_cnt_month_minus_'+str(lag) })\n",
    "        Data['test'] = Data['test'].merge(tmp,\n",
    "                how = 'left',\n",
    "                on = ['item_id', 'shop_id']\n",
    "                )\n",
    "\n",
    "### Add the stats on item_cnt_month for every couple store,item\n",
    "# Only known values are for the train set\n",
    "\n",
    "print(\"Adding item count stats\")\n",
    "\n",
    "# Stats over the months\n",
    "tmp = Data['train'].groupby(['shop_id', 'item_id'], as_index = False).item_cnt_month.agg({\n",
    "    'item_cnt_month_mean': np.mean,\n",
    "    'item_cnt_month_max': np.max\n",
    "})\n",
    "# Warning: if the couple item, shop is not present in the train set for any month, the following will generate a NaN:\n",
    "# * for merge with the train set: this will produce a 0 (all couples exist) > we remove those later as they are all the same\n",
    "# and cannot be used to learn anything\n",
    "# * for merge with evaluation/test set: this will produce a NaN > those lines will be replaced by stats\n",
    "# > this is wrong, the system cannot learn, we have to replace those lines in the eval/test after prediction\n",
    "\n",
    "for set_name in set_list:\n",
    "    Data[set_name] = Data[set_name].merge(tmp,\n",
    "            how = 'left',\n",
    "            on = ['item_id', 'shop_id']\n",
    "            )\n",
    "    \n",
    "# Add the average price per item and shop, over the train data set (average price will be missing for some items)\n",
    "\n",
    "print(\"Adding shop item price stats\")\n",
    "\n",
    "# Average over the months of the train set per item and shop\n",
    "# The mean is not weighted by the sales\n",
    "\n",
    "tmp = Data['train'].groupby(['item_id', 'shop_id'], as_index = False).item_mean_price_shop_month.agg({\n",
    "    'item_shop_mean_price': np.mean\n",
    "})\n",
    "\n",
    "for set_name in set_list:\n",
    "    Data[set_name] = Data[set_name].merge(tmp,\n",
    "            how = 'left',\n",
    "            on = ['item_id', 'shop_id']\n",
    "            )\n",
    "\n",
    "# We remove the couple (item, shop) without any sale from the training set\n",
    "condition = pd.isnull(Data['train'].item_shop_mean_price)\n",
    "Data['train'] = Data['train'][~condition]\n",
    "    \n",
    "    #missing_shop_item_indices = pd.isnull(Data[set_name]['item_shop_mean_price'])\n",
    "    #Data[set_name].loc[missing_shop_item_indices, 'item_shop_mean_price'] = -999\n",
    "\n",
    "print(\"Adding overall item price stats\")    \n",
    "    \n",
    "# Add the average price per item over the train data set (average price will be missing for some items)\n",
    "# The mean is not weighted by the sales\n",
    "\n",
    "tmp = Data['train'].groupby(['item_id'], as_index = False).item_mean_price_shop_month.agg({\n",
    "    'item_overall_mean_price': np.mean\n",
    "})\n",
    "\n",
    "for set_name in set_list:\n",
    "    Data[set_name] = Data[set_name].merge(tmp,\n",
    "            how = 'left',\n",
    "            on = ['item_id']\n",
    "            )\n",
    "    # The item with no sale in the training set will be addressed after prediction\n",
    "    # missing_item_indices = pd.isnull(Data[set_name]['item_overall_mean_price'])\n",
    "    # Data[set_name].loc[missing_item_indices, 'item_overall_mean_price'] = -999\n",
    "\n",
    "# Remove the item_id TO PUT BACK\n",
    "\n",
    "#for set_name in set_list:\n",
    "#    Data[set_name] = Data[set_name].drop(['item_id', 'item_category_id'], axis = 1)\n",
    "    \n",
    "Data['train'] = Data['train'].drop(['item_mean_price_shop_month'], axis = 1)\n",
    "if training:\n",
    "    Data['evaluation'] = Data['evaluation'].drop(['item_mean_price_shop_month'], axis = 1)\n",
    "\n",
    "print(\"Done!\")\n",
    "#Data['evaluation'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>category_cnt_month_max</th>\n",
       "      <th>category_cnt_month_mean</th>\n",
       "      <th>item_cnt_month_minus_12</th>\n",
       "      <th>item_cnt_month_minus_3</th>\n",
       "      <th>item_cnt_month_minus_1</th>\n",
       "      <th>item_cnt_month_mean</th>\n",
       "      <th>item_cnt_month_max</th>\n",
       "      <th>item_shop_mean_price</th>\n",
       "      <th>item_overall_mean_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "      <td>1.442022e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.650000e+01</td>\n",
       "      <td>1.145802e+04</td>\n",
       "      <td>3.143122e+01</td>\n",
       "      <td>2.529925e-01</td>\n",
       "      <td>6.205882e+00</td>\n",
       "      <td>2.013941e+03</td>\n",
       "      <td>4.260401e+01</td>\n",
       "      <td>4.808575e+01</td>\n",
       "      <td>1.536073e-01</td>\n",
       "      <td>1.726465e-01</td>\n",
       "      <td>1.562529e-01</td>\n",
       "      <td>1.473567e-01</td>\n",
       "      <td>2.529925e-01</td>\n",
       "      <td>2.966234e+00</td>\n",
       "      <td>7.898727e+02</td>\n",
       "      <td>7.930833e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.810709e+00</td>\n",
       "      <td>6.133325e+03</td>\n",
       "      <td>1.696204e+01</td>\n",
       "      <td>2.976348e+00</td>\n",
       "      <td>3.323530e+00</td>\n",
       "      <td>8.022460e-01</td>\n",
       "      <td>1.521945e+01</td>\n",
       "      <td>9.141636e+01</td>\n",
       "      <td>5.268633e-01</td>\n",
       "      <td>2.220762e+00</td>\n",
       "      <td>2.417708e+00</td>\n",
       "      <td>2.296853e+00</td>\n",
       "      <td>1.897223e+00</td>\n",
       "      <td>1.115443e+01</td>\n",
       "      <td>1.609214e+03</td>\n",
       "      <td>1.606589e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.200000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.824677e-05</td>\n",
       "      <td>-2.200000e+01</td>\n",
       "      <td>-2.200000e+01</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>-3.529412e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e-02</td>\n",
       "      <td>4.895753e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>6.244000e+03</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>4.317897e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.941176e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>2.010241e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.650000e+01</td>\n",
       "      <td>1.161400e+04</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.014000e+03</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>7.665782e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.823529e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.490000e+02</td>\n",
       "      <td>3.442273e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.666200e+04</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.015000e+03</td>\n",
       "      <td>5.500000e+01</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>1.858289e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.058824e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>7.990000e+02</td>\n",
       "      <td>8.121671e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>2.216900e+04</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>2.253000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.015000e+03</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>2.253000e+03</td>\n",
       "      <td>9.893137e+01</td>\n",
       "      <td>1.305000e+03</td>\n",
       "      <td>1.305000e+03</td>\n",
       "      <td>1.305000e+03</td>\n",
       "      <td>5.862941e+02</td>\n",
       "      <td>2.253000e+03</td>\n",
       "      <td>2.269199e+04</td>\n",
       "      <td>2.269199e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_block_num       item_id       shop_id  item_cnt_month  \\\n",
       "count    1.442022e+07  1.442022e+07  1.442022e+07    1.442022e+07   \n",
       "mean     1.650000e+01  1.145802e+04  3.143122e+01    2.529925e-01   \n",
       "std      9.810709e+00  6.133325e+03  1.696204e+01    2.976348e+00   \n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00   -2.200000e+01   \n",
       "25%      8.000000e+00  6.244000e+03  1.800000e+01    0.000000e+00   \n",
       "50%      1.650000e+01  1.161400e+04  3.000000e+01    0.000000e+00   \n",
       "75%      2.500000e+01  1.666200e+04  4.600000e+01    0.000000e+00   \n",
       "max      3.300000e+01  2.216900e+04  5.900000e+01    2.253000e+03   \n",
       "\n",
       "              month          year  item_category_id  category_cnt_month_max  \\\n",
       "count  1.442022e+07  1.442022e+07      1.442022e+07            1.442022e+07   \n",
       "mean   6.205882e+00  2.013941e+03      4.260401e+01            4.808575e+01   \n",
       "std    3.323530e+00  8.022460e-01      1.521945e+01            9.141636e+01   \n",
       "min    1.000000e+00  2.013000e+03      0.000000e+00            1.000000e+00   \n",
       "25%    3.000000e+00  2.013000e+03      3.700000e+01            1.100000e+01   \n",
       "50%    6.000000e+00  2.014000e+03      4.000000e+01            2.100000e+01   \n",
       "75%    9.000000e+00  2.015000e+03      5.500000e+01            5.200000e+01   \n",
       "max    1.200000e+01  2.015000e+03      8.300000e+01            2.253000e+03   \n",
       "\n",
       "       category_cnt_month_mean  item_cnt_month_minus_12  \\\n",
       "count             1.442022e+07             1.442022e+07   \n",
       "mean              1.536073e-01             1.726465e-01   \n",
       "std               5.268633e-01             2.220762e+00   \n",
       "min               3.824677e-05            -2.200000e+01   \n",
       "25%               4.317897e-02             0.000000e+00   \n",
       "50%               7.665782e-02             0.000000e+00   \n",
       "75%               1.858289e-01             0.000000e+00   \n",
       "max               9.893137e+01             1.305000e+03   \n",
       "\n",
       "       item_cnt_month_minus_3  item_cnt_month_minus_1  item_cnt_month_mean  \\\n",
       "count            1.442022e+07            1.442022e+07         1.442022e+07   \n",
       "mean             1.562529e-01            1.473567e-01         2.529925e-01   \n",
       "std              2.417708e+00            2.296853e+00         1.897223e+00   \n",
       "min             -2.200000e+01           -5.000000e+00        -3.529412e-01   \n",
       "25%              0.000000e+00            0.000000e+00         2.941176e-02   \n",
       "50%              0.000000e+00            0.000000e+00         8.823529e-02   \n",
       "75%              0.000000e+00            0.000000e+00         2.058824e-01   \n",
       "max              1.305000e+03            1.305000e+03         5.862941e+02   \n",
       "\n",
       "       item_cnt_month_max  item_shop_mean_price  item_overall_mean_price  \n",
       "count        1.442022e+07          1.442022e+07             1.442022e+07  \n",
       "mean         2.966234e+00          7.898727e+02             7.930833e+02  \n",
       "std          1.115443e+01          1.609214e+03             1.606589e+03  \n",
       "min          0.000000e+00          9.000000e-02             4.895753e+00  \n",
       "25%          1.000000e+00          1.990000e+02             2.010241e+02  \n",
       "50%          1.000000e+00          3.490000e+02             3.442273e+02  \n",
       "75%          2.000000e+00          7.990000e+02             8.121671e+02  \n",
       "max          2.253000e+03          2.269199e+04             2.269199e+04  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['train'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorder the columns alphabetically to avoid issues with columns position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    set_list = ['train','evaluation']\n",
    "else:\n",
    "    set_list = ['train','test']\n",
    "\n",
    "for set_name in set_list:\n",
    "    Data[set_name].sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "DATA_LEARNING_FILE = \"../data/sales-20180130b\"\n",
    "DATA_EVALUATION_FILE = \"../data/evaluation-20180130b\"\n",
    "DATA_TEST_FILE = \"../data/test-201801230b\"\n",
    "\n",
    "Data['train'].to_pickle(DATA_LEARNING_FILE)\n",
    "if training:\n",
    "    Data['evaluation'].to_pickle(DATA_EVALUATION_FILE)\n",
    "else:\n",
    "    Data['test'].to_pickle(DATA_TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20180127c : with windsorization 0.999 , removing rows for store, item without any sale\n",
    "# 20180127d : idem without windsorization \n",
    "# 20180127e : idem with windsorization 0.9999\n",
    "# 20180127f : idem with windsorization 0.99\n",
    "# 20180127g : idem with windsorization 0.99, with full set\n",
    "# 20180127h : idem with windsorization 0.999, with full set\n",
    "# 20180128c : windsorization on train only 0.999, with train/eval split\n",
    "# 20180128d : windsorization on train only 0.99, with train/eval split\n",
    "# 20180128e : no windsorization, with train/eval split\n",
    "# 20180128f : with windsor 0.999 on price, with train/eval split\n",
    "# 20180128g : with windsor 0.999 on price, without eval\n",
    "# 201801230a : with windsor 0.999 on price, with eval, with lagged item_count, shop_id, item_category_id\n",
    "# 201801230b : with windsor 0.999 on price, without eval, with lagged item_count, shop_id, item_category_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart it to retrieve data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "training = True\n",
    "\n",
    "DATA_LEARNING_FILE = \"../data/sales-20180130a\"\n",
    "DATA_EVALUATION_FILE = \"../data/evaluation-20180130a\"\n",
    "\n",
    "Data = {}\n",
    "\n",
    "Data['train'] = pd.read_pickle(DATA_LEARNING_FILE)\n",
    "if training:\n",
    "    Data['evaluation'] = pd.read_pickle(DATA_EVALUATION_FILE)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-17fcd64bf07e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "Data['train'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train/eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipping  = True\n",
    "\n",
    "# Random split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train_set, test_set = train_test_split(Data['train'], test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Remove the first year to decrease training time (and after we will add delayed values)\n",
    "Data['train'] = Data['train'][Data['train'].date_block_num >11].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "x_train = Data['train'].drop(['item_cnt_month'], axis = 1)\n",
    "\n",
    "if clipping:\n",
    "    y_train = Data['train'].item_cnt_month.clip(0,20)\n",
    "else:\n",
    "    y_train = Data['train'].item_cnt_month\n",
    "\n",
    "# I should remove the evaluation prediction rows with missings category\n",
    "\n",
    "if training:\n",
    "    x_eval = Data['evaluation'].drop(['item_cnt_month'], axis = 1)\n",
    "    y_eval = Data['evaluation'].item_cnt_month\n",
    "\n",
    "del(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_evaluation(model_reg, x_train, y_train, x_test, y_test, use_average = True): \n",
    "    sales_predictions = model_reg.predict(x_train)\n",
    "    mse = mean_squared_error(y_train, sales_predictions)\n",
    "    rmse_train = np.sqrt(mse)\n",
    "\n",
    "    sales_predictions = pd.DataFrame({'pred': model_reg.predict(x_test.fillna(0))})\n",
    "    \n",
    "    if use_average:\n",
    "        # replace the shop, item rows with no values, with the average on the category \n",
    "        missing_shop_item_rows = pd.isnull(x_test.item_shop_mean_price)\n",
    "        print('Missing lines for shop,items: ', len(x_test[missing_shop_item_rows]))\n",
    "        sales_predictions.loc[missing_shop_item_rows, 'pred'] = x_test[missing_shop_item_rows].category_cnt_month_mean\n",
    "    \n",
    "    # replace the shop, category with no values, with 0 (the shop is not selling this category)\n",
    "    missing_shop_category_rows = pd.isnull(sales_predictions.pred)  \n",
    "    print('Missing lines for shop,category: ', len(x_test[missing_shop_category_rows]))\n",
    "    sales_predictions.loc[missing_shop_category_rows, 'pred'] = 0\n",
    "    \n",
    "    mse = mean_squared_error(y_test.clip(0,20), sales_predictions.pred.clip(0,20))\n",
    "    rmse_test = np.sqrt(mse)\n",
    "\n",
    "    print(\"train error: \", '{0:.3f}'.format(rmse_train), \"evaluation error: \", '{0:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=125, n_jobs=5, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df_reg = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
    "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=1,\n",
    "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=125, n_jobs=5, oob_score=False, random_state=None,\n",
    "           verbose=0, warm_start=False)\n",
    "df_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing lines for shop,items:  121115\n",
      "Missing lines for shop,category:  5413\n",
      "train error:  0.579 evaluation error:  0.968\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(df_reg, x_train, y_train, x_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with 20180127c\n",
    "# max_depth=15, n_estimators=20, max_features: 3 : 1.004 / 1.403\n",
    "# max_depth=20, n_estimators=20, max_features: 2 : 0.839 / 1.399\n",
    "# max_depth=20, n_estimators=20, max_features: 3 : 0.818 / 1.394\n",
    "# max_depth=20, n_estimators=50, max_features: 3 : 0.834 / 1.391 > best\n",
    "# max_depth=25, n_estimators=20, max_features: 3 : 0.657 / 1.404\n",
    "# max_depth=20, n_estimators=20, max_features: 4 : 0.795 / 1.410\n",
    "\n",
    "# with 20180127d, max_depth=20, n_estimators=50, max_features: 3\n",
    "# train error: 1.104 evaluation error:  4.596 > windsorization is essential!!\n",
    "\n",
    "# with 20180127e, max_depth=20, n_estimators=25, max_features: 3\n",
    "# train error:  0.949 evaluation error:  1.612 still not as good\n",
    "\n",
    "# with 20180127f, max_depth=20, n_estimators=25, max_features: 3\n",
    "# train error:  0.696 evaluation error:  1.027 > best but beware, \n",
    "#I may just be reducing the variance of the evaluation set :)  \n",
    "# let check with the Kaggle :) \n",
    "# with clip 0-20 train error:  0.692 evaluation error:  0.924 (meaningless as it was windsored)\n",
    "\n",
    "# with 20180127h, max_depth=20, n_estimators=50, max_features: 3, windsor:0.999, full set\n",
    "# kaggle: 1.41\n",
    "\n",
    "# with 20180127g, max_depth=20, n_estimators=50, max_features: 3, windsor:0.99, full set\n",
    "# kaggle: 1.40 > best\n",
    "\n",
    "# Conclusion: we have brought the results much closer 0.7 / 1.0 / 1.4\n",
    "# but we are still higher than before ??? \n",
    "# does the category do help or harm?\n",
    "\n",
    "# with 20180127f, removing category stat, max_depth=20, n_estimators=25, max_features: 3, windsor:0.99, full set\n",
    "# 0.677 evaluation error:  1.043 : slightly worse\n",
    "\n",
    "# with 20180128d, max_depth=20, n_estimators=25, max_features: 3, windsor on train 0.99\n",
    "# train error:  0.601 evaluation error:  5.237\n",
    "# with clipping 0-20: train error:  0.607 evaluation error:  0.979\n",
    "\n",
    "# with 20180128c, max_depth=20, n_estimators=25, max_features: 3, windsor on train 0.999\n",
    "# train error:  0.743 evaluation error:  5.039\n",
    "# with clipping 0-20: train error:  0.743 evaluation error:  0.996\n",
    "\n",
    "# with 20180128e, max_depth=20, n_estimators=25, max_features: 3, no windsor on train\n",
    "# train error:  1.095 evaluation error:  4.702\n",
    "# with clipping 0-20 at evaluation (y_eval and pred): train error:  1.094 evaluation error:  1.002\n",
    "# with clipping 0-20 of y_train train error:  0.616 evaluation error:  0.975 > best\n",
    "\n",
    "# with 20180128f, max_depth=20, n_estimators=25, max_features: 3,  windsor 0.999 on price only, clipping 0-20 on train\n",
    "# train error:  0.616 evaluation error:  0.973 > best\n",
    "\n",
    "# with 20180128g, max_depth=20, n_estimators=100, max_features: 3,  windsor 0.999 on price only, clipping 0-20 on train\n",
    "# no eval\n",
    "# kaggle: 1.02119\n",
    "\n",
    "# with 20180130a, max_depth=20, n_estimators=25, max_features: 3,  with lagged features, item_id, category_item_id\n",
    "# 0.567 evaluation error:  0.962 > overfitted...\n",
    "\n",
    "# with 20180130b, max_depth=20, n_estimators=25, max_features: 3,  with lagged features, without item_id, category_item_id\n",
    "# 0.579 evaluation error:  0.968 > actually slightly worse\n",
    "# Kaggle: \n",
    "\n",
    "train error:  0.579 evaluation error:  0.968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(df_reg, '../models/randomforest_20180128g.pkl')\n",
    "#df_reg = joblib.load('../models/randomforest_20180127g.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = df_reg.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# You can experiment with many other options here, using the same .fit() and .predict()\n",
    "# methods; see http://scikit-learn.org\n",
    "# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\n",
    "gbm = xgb.XGBRegressor(max_depth=3, \n",
    "                       n_estimators=300, \n",
    "                       learning_rate=0.05,\n",
    "                       n_jobs = 5).fit(x_train, y_train)\n",
    "\n",
    "if training:\n",
    "    model_evaluation(gbm, x_train, y_train, x_eval, y_eval, use_average = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [10,50, 100], 'max_features': [2,4,6], 'max_depth': [5, 10, 20]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, n_jobs = 4,\n",
    "                          scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_evaluation(grid_search.best_estimator_, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt_reg = GradientBoostingRegressor(learning_rate = 0.1)\n",
    "gbrt_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_test =  test_set.drop(['item_cnt_month'], axis = 1)\n",
    "y_test = test_set.item_cnt_month\n",
    "\n",
    "model_evaluation(gbrt_reg, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20180120-01 with default randomForestRegressor, only 4 features, eval: 4.90 (not better through grid search)\n",
    "* idem, but adding the item_category, eval: 5.4 vs 2.42 (train set)\n",
    "* with GBRT, eval = 7.1 vs 7.36(train set) > not working\n",
    "* with Random Forest, adding the min, max, mean of sales per store,item eval 4.86 vs 2.04\n",
    "* idem, removing the item_id: train error:  2.16 test_error:  4.64\n",
    "* idem, selecting the best estimator: train error:  1.93 test_error:  4.56\n",
    "* adding the average price per item, per shop and overall, max_features 3, n_estimators=50 train error:  train error:  1.98 test_error:  4.45 (best)\n",
    "* with one hot encoding of the shop_id: train error:  1.97 test_error:  4.90\n",
    "* with one hot encoding of the item_category_id: train error:  2.07 test_error:  4.79\n",
    "* with windsorization of the count_item_day, and the price the results improve a lot: train error:  1.08 test_error:  2.91\n",
    "* adding the 0 values: train error:  0.33 test_error:  0.94 > kaggle 1.27 without putting missing items to 0 this does not change a thing actually)\n",
    "* item category is useless > split and provide some price per category\n",
    "* with new train/test set, not removing the new item prediction: train error:  0.34 test_error:  1.94 / Kaggle: 2.61 (I did not remove the 0 prediction there, nor retrain on the full set)\n",
    "* with category stats randomforest_20180126b: tain_error:  0.35 test_error:  1.75 Kaggle: 2.4 \n",
    "* idem, removing missing items: Kaggle: 2.42 it is worse, removing missing category is better!\n",
    "* with full training: Kaggle: 2.58!!! maybe I am just tragically overfitting\n",
    "* trying to reduce overfitting by putting max_features = 2/ min_samples_leaf=2: train error:  0.657 test_error:  1.805\n",
    "* removing the mean, removing the artificial item deletion from validation set: train error:  0.339 evaluation error:  1.768 Kaggle: \n",
    "\n",
    "* with removal of missing shop, item rows, and replacement by avrage and 0, 100 estimators: train error:  0.400 evaluation error:  1.417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Submission preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>category_cnt_month_max</th>\n",
       "      <th>category_cnt_month_mean</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_month_max</th>\n",
       "      <th>item_cnt_month_mean</th>\n",
       "      <th>item_cnt_month_minus_1</th>\n",
       "      <th>item_cnt_month_minus_12</th>\n",
       "      <th>item_cnt_month_minus_3</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_overall_mean_price</th>\n",
       "      <th>item_shop_mean_price</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.151388</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5037</td>\n",
       "      <td>1960.580473</td>\n",
       "      <td>1693.518519</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.151388</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5233</td>\n",
       "      <td>844.516003</td>\n",
       "      <td>859.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.119545</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5232</td>\n",
       "      <td>792.527697</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.296553</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.119545</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5039</td>\n",
       "      <td>1920.578933</td>\n",
       "      <td>1896.305556</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.296553</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5041</td>\n",
       "      <td>3814.782708</td>\n",
       "      <td>3915.666667</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5046</td>\n",
       "      <td>326.776255</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.852941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5319</td>\n",
       "      <td>295.510542</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.296553</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5003</td>\n",
       "      <td>3977.846154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.279823</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.147059</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4806</td>\n",
       "      <td>165.604361</td>\n",
       "      <td>164.429167</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.296553</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4843</td>\n",
       "      <td>9891.333821</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4607</td>\n",
       "      <td>307.913583</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.110201</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4869</td>\n",
       "      <td>1271.935406</td>\n",
       "      <td>1284.714286</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.119545</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.882353</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4870</td>\n",
       "      <td>938.018061</td>\n",
       "      <td>988.882716</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.151388</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.323529</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4872</td>\n",
       "      <td>1064.455805</td>\n",
       "      <td>1118.538690</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>34</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4874</td>\n",
       "      <td>1626.227727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4678</td>\n",
       "      <td>314.122881</td>\n",
       "      <td>315.666667</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.279823</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4892</td>\n",
       "      <td>984.549893</td>\n",
       "      <td>998.976190</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.296553</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4964</td>\n",
       "      <td>2303.987415</td>\n",
       "      <td>2999.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  category_cnt_month_max  category_cnt_month_mean  date_block_num  \\\n",
       "0    0                    46.0                 0.151388              34   \n",
       "1    1                    28.0                 0.061731              34   \n",
       "2    2                    46.0                 0.151388              34   \n",
       "3    3                    26.0                 0.119545              34   \n",
       "4    4                    58.0                 0.296553              34   \n",
       "5    5                    26.0                 0.119545              34   \n",
       "6    6                    58.0                 0.296553              34   \n",
       "7    7                    28.0                 0.061731              34   \n",
       "8    8                    28.0                 0.061731              34   \n",
       "9    9                    58.0                 0.296553              34   \n",
       "10  10                    87.0                 0.279823              34   \n",
       "11  11                    58.0                 0.296553              34   \n",
       "12  12                    28.0                 0.061731              34   \n",
       "13  13                     7.0                 0.110201              34   \n",
       "14  14                    26.0                 0.119545              34   \n",
       "15  15                    46.0                 0.151388              34   \n",
       "16  16                     6.0                 0.025678              34   \n",
       "17  17                    28.0                 0.061731              34   \n",
       "18  18                    87.0                 0.279823              34   \n",
       "19  19                    58.0                 0.296553              34   \n",
       "\n",
       "    item_category_id  item_cnt_month_max  item_cnt_month_mean  \\\n",
       "0                 19                 3.0             0.382353   \n",
       "1                 55                 NaN                  NaN   \n",
       "2                 19                 3.0             0.294118   \n",
       "3                 23                 1.0             0.029412   \n",
       "4                 20                 NaN                  NaN   \n",
       "5                 23                 3.0             0.323529   \n",
       "6                 20                 3.0             0.147059   \n",
       "7                 55                 5.0             0.235294   \n",
       "8                 55                28.0             1.852941   \n",
       "9                 20                 0.0             0.000000   \n",
       "10                30                 8.0             2.147059   \n",
       "11                20                 1.0             0.029412   \n",
       "12                55                 1.0             0.147059   \n",
       "13                22                 6.0             0.529412   \n",
       "14                23                 8.0             2.882353   \n",
       "15                19                10.0             2.323529   \n",
       "16                72                 0.0             0.000000   \n",
       "17                55                 1.0             0.088235   \n",
       "18                30                 9.0             0.735294   \n",
       "19                20                 3.0             0.147059   \n",
       "\n",
       "    item_cnt_month_minus_1  item_cnt_month_minus_12  item_cnt_month_minus_3  \\\n",
       "0                      0.0                      1.0                     3.0   \n",
       "1                      NaN                      NaN                     NaN   \n",
       "2                      1.0                      0.0                     1.0   \n",
       "3                      0.0                      0.0                     1.0   \n",
       "4                      NaN                      NaN                     NaN   \n",
       "5                      1.0                      0.0                     0.0   \n",
       "6                      2.0                      0.0                     0.0   \n",
       "7                      0.0                      1.0                     0.0   \n",
       "8                      0.0                      5.0                     2.0   \n",
       "9                      0.0                      0.0                     0.0   \n",
       "10                     3.0                      2.0                     5.0   \n",
       "11                     0.0                      0.0                     0.0   \n",
       "12                     0.0                      0.0                     0.0   \n",
       "13                     0.0                      0.0                     1.0   \n",
       "14                     2.0                      5.0                     3.0   \n",
       "15                     6.0                      5.0                     2.0   \n",
       "16                     0.0                      0.0                     0.0   \n",
       "17                     0.0                      1.0                     0.0   \n",
       "18                     2.0                      0.0                     2.0   \n",
       "19                     0.0                      0.0                     0.0   \n",
       "\n",
       "    item_id  item_overall_mean_price  item_shop_mean_price  month  shop_id  \\\n",
       "0      5037              1960.580473           1693.518519     11        5   \n",
       "1      5320                      NaN                   NaN     11        5   \n",
       "2      5233               844.516003            859.000000     11        5   \n",
       "3      5232               792.527697            599.000000     11        5   \n",
       "4      5268                      NaN                   NaN     11        5   \n",
       "5      5039              1920.578933           1896.305556     11        5   \n",
       "6      5041              3814.782708           3915.666667     11        5   \n",
       "7      5046               326.776255            324.000000     11        5   \n",
       "8      5319               295.510542            299.000000     11        5   \n",
       "9      5003              3977.846154                   NaN     11        5   \n",
       "10     4806               165.604361            164.429167     11        5   \n",
       "11     4843              9891.333821           9999.000000     11        5   \n",
       "12     4607               307.913583            299.000000     11        5   \n",
       "13     4869              1271.935406           1284.714286     11        5   \n",
       "14     4870               938.018061            988.882716     11        5   \n",
       "15     4872              1064.455805           1118.538690     11        5   \n",
       "16     4874              1626.227727                   NaN     11        5   \n",
       "17     4678               314.122881            315.666667     11        5   \n",
       "18     4892               984.549893            998.976190     11        5   \n",
       "19     4964              2303.987415           2999.000000     11        5   \n",
       "\n",
       "    year  \n",
       "0   2015  \n",
       "1   2015  \n",
       "2   2015  \n",
       "3   2015  \n",
       "4   2015  \n",
       "5   2015  \n",
       "6   2015  \n",
       "7   2015  \n",
       "8   2015  \n",
       "9   2015  \n",
       "10  2015  \n",
       "11  2015  \n",
       "12  2015  \n",
       "13  2015  \n",
       "14  2015  \n",
       "15  2015  \n",
       "16  2015  \n",
       "17  2015  \n",
       "18  2015  \n",
       "19  2015  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_TEST_FILE = \"../data/test-201801230b\"\n",
    "\n",
    "Data = {}\n",
    "\n",
    "Data['test'] = pd.read_pickle(DATA_TEST_FILE)\n",
    "\n",
    "Data['test'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing lines for shop,items:  102796\n",
      "Missing lines for shop,category:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.061731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.953177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.044127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.296553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.532677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.768199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.172027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.629908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.296553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  item_cnt_month\n",
       "0   0        0.455219\n",
       "1   1        0.061731\n",
       "2   2        0.953177\n",
       "3   3        0.044127\n",
       "4   4        0.296553\n",
       "5   5        0.532677\n",
       "6   6        0.768199\n",
       "7   7        0.172027\n",
       "8   8        0.629908\n",
       "9   9        0.296553"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_average = True\n",
    "\n",
    "X_test = Data['test'].drop(['ID'], axis = 1)\n",
    "\n",
    "# Option 1\n",
    "# It trust the model will learn from the category count for the missing item - \n",
    "# for the missing category, I set the prediction to 0\n",
    "# missing_shop_item_indices = pd.isnull(Data['test']['item_cnt_month_mean'])\n",
    "# This is not improving the score!\n",
    "\n",
    "predictions = pd.DataFrame({'pred': df_reg.predict(X_test.fillna(0)).clip(0,20)})\n",
    "\n",
    "# replace the shop, item rows with no values, with the average on the category\n",
    "\n",
    "if use_average:\n",
    "        # replace the shop, item rows with no values, with the average on the category \n",
    "        missing_shop_item_rows = pd.isnull(X_test.item_shop_mean_price)\n",
    "        print('Missing lines for shop,items: ', len(X_test[missing_shop_item_rows]))\n",
    "        predictions.loc[missing_shop_item_rows, 'pred'] = X_test[missing_shop_item_rows].category_cnt_month_mean\n",
    "\n",
    "# for the shop with not category, replace with \n",
    "\n",
    "missing_shop_category_rows = pd.isnull(predictions.pred)\n",
    "print('Missing lines for shop,category: ', len(X_test[missing_shop_category_rows]))\n",
    "predictions.loc[missing_shop_category_rows, 'pred'] = 0\n",
    "\n",
    "# Create the submission file:\n",
    "\n",
    "submission = data_load['sample_submission'].copy()\n",
    "\n",
    "submission.loc[:, 'item_cnt_month'] = predictions.pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBMISSION_FILE = \"../data/sales_sub_20180130b.csv\"\n",
    "\n",
    "submission.to_csv(SUBMISSION_FILE, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding (optional, only for DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding of shop_id\n",
    "# The test set has only a few shops, so we have to use scikitlearn onehotencoder\n",
    "\n",
    "cols = ['shop_id']\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# FIT\n",
    "enc.fit(Data['train'][cols])\n",
    "\n",
    "# Transform\n",
    "for set_name in ['train', 'test']:\n",
    "    vec_data= pd.DataFrame(enc.transform(Data[set_name][cols]).toarray())\n",
    "    vec_data.columns = [\"shop_id_\" + str(i) for i in range(enc.feature_indices_[1])]\n",
    "    vec_data.index = Data[set_name].index\n",
    "    Data[set_name] = Data[set_name].drop(cols, axis=1)\n",
    "    Data[set_name] = Data[set_name].join(vec_data)\n",
    "    \n",
    "# One hot encoding of item_category_id\n",
    "# The test set has only a few shops, so we have to use scikitlearn onehotencoder\n",
    "\n",
    "cols = ['item_category_id']\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# FIT\n",
    "enc.fit(Data['train'][cols])\n",
    "\n",
    "# Transform\n",
    "for set_name in ['train', 'test']:\n",
    "    vec_data= pd.DataFrame(enc.transform(Data[set_name][cols]).toarray())\n",
    "    vec_data.columns = [\"item_category_id_\" + str(i) for i in range(enc.feature_indices_[1])]\n",
    "    vec_data.index = Data[set_name].index\n",
    "    Data[set_name] = Data[set_name].drop(cols, axis=1)\n",
    "    Data[set_name] = Data[set_name].join(vec_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "sales_predictions = pd.DataFrame(Data['evaluation'].item_cnt_month.copy())\n",
    "sales_predictions.item_cnt_month = 0.28\n",
    "\n",
    "\n",
    "\n",
    "mse = mean_squared_error(Data['evaluation'].item_cnt_month, sales_predictions.item_cnt_month)\n",
    "rmse_test = np.sqrt(mse)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['train']['item_cnt_month_minus_12'] = 0\n",
    "Data['train']['item_cnt_month_minus_3'] = 0\n",
    "Data['train']['item_cnt_month_minus_1'] = 0 \n",
    "\n",
    "for month in range(12, 33,1):\n",
    "    condition = Data['train'].date_block_num == month\n",
    "    Data['train'].loc[condition, 'item_cnt_month_minus_12'] = Data['train'][Data['train'].date_block_num == (month-12)]\n",
    "    Data['train'].loc[condition, 'item_cnt_month_minus_3'] = Data['train'][Data['train'].date_block_num == (month-3)]\n",
    "    Data['train'].loc[condition, 'item_cnt_month_minus_1'] = Data['train'][Data['train'].date_block_num == (month-1)]\n",
    "\n",
    "if training:\n",
    "    Data['evaluation']['item_cnt_month_minus_12'] = 0\n",
    "    Data['evaluation']['item_cnt_month_minus_3'] = 0\n",
    "    Data['evaluation']['item_cnt_month_minus_1'] = 0 \n",
    "\n",
    "    Data['evaluation'].loc[:, 'item_cnt_month_minus_12'] = Data['train'][Data['train'].date_block_num == (33-12)]\n",
    "    Data['evaluation'].loc[:, 'item_cnt_month_minus_3'] = Data['train'][Data['train'].date_block_num == (33-3)]\n",
    "    Data['evaluation'].loc[:, 'item_cnt_month_minus_1'] = Data['train'][Data['train'].date_block_num == (33-1)]    \n",
    "\n",
    "# Merge version for evaluation and test\n",
    "Data['test']['item_cnt_month_minus_12'] = 0\n",
    "Data['test']['item_cnt_month_minus_3'] = 0\n",
    "Data['test']['item_cnt_month_minus_1'] = 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
