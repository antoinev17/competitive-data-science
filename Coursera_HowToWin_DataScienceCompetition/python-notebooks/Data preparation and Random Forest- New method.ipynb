{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "* Step 1: prepare the training and evaluation data set\n",
    "* Step 2: training with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import calendar\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_extraction\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "\n",
    "# To use part or all the train set\n",
    "training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load all Files (hey must be in input directory in a brother directory of the notebook)\n",
    "data_load = {\n",
    "    'item_categories': pd.read_csv('../input/item_categories.csv'), \n",
    "    'items': pd.read_csv('../input/items.csv'), \n",
    "    'sales_train': pd.read_csv('../input/sales_train_v2.csv'),\n",
    "    'sample_submission': pd.read_csv('../input/sample_submission.csv'),\n",
    "    'shops': pd.read_csv('../input/shops.csv'),\n",
    "    'test': pd.read_csv('../input/test.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = {}\n",
    "\n",
    "# Sales data \n",
    "data_load['sales_train']['date'] = pd.to_datetime(data_load['sales_train']['date'], format = \"%d.%m.%Y\")\n",
    "\n",
    "#Data['sales']['day'] = transactions['date'].dt.day\n",
    "data_load['sales_train']['month'] = data_load['sales_train']['date'].dt.month\n",
    "data_load['sales_train']['year'] = data_load['sales_train']['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_load['sales_train'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training/evaluation set, with similar pattern as the test set:\n",
    "* All shops in both sets\n",
    "* evaluation set on the last month\n",
    "* unknown items in the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['train'] = data_load['sales_train'].groupby(['date_block_num', 'shop_id', 'item_id'], as_index = False).agg({\n",
    "    'item_price': np.mean,\n",
    "    'item_cnt_day': np.sum\n",
    "}).rename(columns = {'item_cnt_day': 'item_shop_count',\n",
    "          'item_price': 'item_shop_price' })\n",
    "\n",
    "if training: \n",
    "    \n",
    "    # Split on date to create the evaluation set\n",
    "    \n",
    "    print(\"Preparing the evaluation set\")\n",
    "    \n",
    "    condition = Data['train']['date_block_num']==33\n",
    "    Data['evaluation'] = Data['train'][condition]\n",
    "    Data['train'] = Data['train'][~condition]\n",
    "    \n",
    "    print(\"sizes:\" ,Data['evaluation'].shape, Data['train'].shape)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Prepare the test set\n",
    "    \n",
    "    print(\"Preparing the test set\")\n",
    "\n",
    "    Data['test'] = data_load['test'].copy()\n",
    "    Data['test']['month'] = 11\n",
    "    Data['test']['year'] = 2015\n",
    "    Data['test']['date_block_num'] = 34\n",
    "\n",
    "    cols = ['ID', 'date_block_num', 'item_id', 'shop_id','month', 'year']\n",
    "    Data['test'] = Data['test'][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " Data['train'][( Data['train'].shop_id == 5) & ( Data['train'].item_id == 485)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winsorization - on training set only to evaluate the effect on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_limit = Data['train'].item_shop_price.quantile([0.0, 0.999])[0.999]\n",
    "prices = Data['train'].item_shop_price\n",
    "Data['train'].loc[(prices > price_limit), 'item_shop_price'] = price_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    set_list = ['train', 'evaluation']\n",
    "else:\n",
    "    set_list = ['train']\n",
    "    \n",
    "months = data_load['sales_train'].groupby(['month', 'year'], as_index = False).date_block_num.first()\n",
    "\n",
    "for set_name in set_list:\n",
    "\n",
    "    # Add the missing rows date_block_num,shop_id, item_id with item_cnt_month = 0\n",
    "    \n",
    "    print('Adding the missing rows for', set_name, 'set...')\n",
    "    \n",
    "    # From the assignment of week 3\n",
    "    # It differs from old method, because we do not consider the shops without sales or the items not sold during a month\n",
    "    # whereas before we were considering all combinations, and afterwards we were removing the couple shop, item\n",
    "    # with no sales on the full period: that means 10M rows vs 14M and a mean value of 0.3343 which is too high compare to \n",
    "    # the test set: 0.28\n",
    "    # However, it solves the issue of items not sold for months impacting the average\n",
    "    index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "    # For every month we create a grid from all shops/items combinations from that month\n",
    "    grid = [] \n",
    "    for block_num in Data[set_name]['date_block_num'].unique():\n",
    "        cur_shops = Data[set_name][Data[set_name]['date_block_num']==block_num]['shop_id'].unique()\n",
    "        cur_items = Data[set_name][Data[set_name]['date_block_num']==block_num]['item_id'].unique()\n",
    "        grid.append(np.array(list(itertools.product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "    #turn the grid into pandas dataframe\n",
    "    grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "    #join aggregated data to the grid\n",
    "    Data[set_name] = pd.merge(grid,Data[set_name],how='left',on=index_cols)\n",
    "    #sort the data\n",
    "    Data[set_name].sort_values(['date_block_num','shop_id','item_id'],inplace=True)\n",
    "\n",
    "    # Add the month and year\n",
    "    \n",
    "    Data[set_name] = Data[set_name].merge(months,\n",
    "                   how = 'left',\n",
    "                   on = ['date_block_num'])\n",
    "    \n",
    "    # For new rows missing values:\n",
    "    \n",
    "    Data[set_name].item_shop_count = Data[set_name].item_shop_count.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://mlwhiz.com/blog/2017/12/26/How_to_win_a_data_science_competition/\n",
    "\n",
    "lag_variables  = ['item_shop_count', 'item_shop_price']\n",
    "lags = [1, 3 , 6 , 12]\n",
    "for lag in lags:\n",
    "    \n",
    "    print('Adding lag:', lag)\n",
    "    \n",
    "    train_df = Data['train'].copy()\n",
    "    train_df.date_block_num+=lag\n",
    "    train_df = train_df[['date_block_num','shop_id','item_id']+lag_variables]\n",
    "    train_df.columns = ['date_block_num','shop_id','item_id']+ [lag_feat+'_lag_'+str(lag) for lag_feat in lag_variables]\n",
    "    Data['train'] = pd.merge(Data['train'], train_df,on=['date_block_num','shop_id','item_id'] ,how='left')\n",
    "    \n",
    "    if training:\n",
    "        Data['evaluation'] = pd.merge(Data['evaluation'], train_df,on=['date_block_num','shop_id','item_id'] ,how='left')\n",
    "    else:\n",
    "        Data['test'] = pd.merge(Data['test'], train_df,on=['date_block_num','shop_id','item_id'] ,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['train'][-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Data['train'].copy()\n",
    "b = Data['evaluation'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['train'] = a.copy()\n",
    "Data['evaluation'] = b.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_mean_encoding(enc_cols, \n",
    "                      mean_encodings, \n",
    "                      label_suffix, \n",
    "                      price_rename, \n",
    "                      count_rename, \n",
    "                      train_set, \n",
    "                      test_set):\n",
    "             \n",
    "    # Create the encoding on the train set\n",
    "    tmp = Data[train_set].groupby(enc_cols, as_index = False).agg(mean_encodings)\\\n",
    "        .rename(columns = {'item_shop_price': price_rename,\n",
    "                            'item_shop_count': count_rename})\n",
    "    tmp.columns = [col[0] if col[-1]=='' else col[0] + '_' + col[-1] + label_suffix for col in tmp.columns.values]\n",
    "\n",
    "    # Add the encoding on each set\n",
    " \n",
    "    Data[train_set] = Data[train_set].merge(tmp,\n",
    "            how = 'left',\n",
    "            on = enc_cols\n",
    "            )\n",
    "    \n",
    "    Data[test_set] =  Data[test_set].merge(tmp,\n",
    "            how = 'left',\n",
    "            on = enc_cols\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Measures to use for the mean encoding\n",
    "mean_encodings = {'item_shop_price':['max','mean'], 'item_shop_count':['max', 'mean']}\n",
    "\n",
    "if training:\n",
    "    test_set = 'evaluation'\n",
    "else:\n",
    "    test_set = 'test'\n",
    "    \n",
    "for set_name in ['train', test_set]:\n",
    "    Data[set_name] = Data[set_name].merge(data_load['items'],\n",
    "            how = 'left',\n",
    "            on = 'item_id',\n",
    "            ).drop(['item_name'], axis = 1)\n",
    "\n",
    "### Add the mean encoding per item_category\n",
    "\n",
    "print(\"Adding shop category stats\")\n",
    "\n",
    "add_mean_encoding(enc_cols=['shop_id', 'item_category_id'],\n",
    "                  mean_encodings = mean_encodings,\n",
    "                  label_suffix='_over_months',\n",
    "                  price_rename='category_shop_price',\n",
    "                  count_rename='category_shop_count',\n",
    "                  train_set = 'train',\n",
    "                  test_set = test_set)\n",
    "    \n",
    "# Add the average price per item and shop, over the train data set (average price will be missing for some items)\n",
    "\n",
    "print(\"Adding shop item stats\")\n",
    "\n",
    "add_mean_encoding(enc_cols=['shop_id', 'item_id'],\n",
    "                  mean_encodings = mean_encodings,\n",
    "                  label_suffix='_over_months',\n",
    "                  price_rename='item_shop_price',\n",
    "                  count_rename='item_shop_count',\n",
    "                  train_set = 'train',\n",
    "                  test_set = test_set)\n",
    "\n",
    "# Add the average price per item over the train data set (average price will be missing for some items)\n",
    "\n",
    "print(\"Adding overall item stats\")  \n",
    "\n",
    "add_mean_encoding(enc_cols=['item_id'],\n",
    "                  mean_encodings = mean_encodings,\n",
    "                  label_suffix='_over_all',\n",
    "                  price_rename='item_price',\n",
    "                  count_rename='item_count',\n",
    "                  train_set = 'train',\n",
    "                  test_set = test_set)\n",
    "\n",
    "# Add the mean encodings per shop over all\n",
    "\n",
    "print(\"Adding overall shop stats\")   \n",
    "\n",
    "add_mean_encoding(enc_cols=['shop_id'],\n",
    "                  mean_encodings = mean_encodings,\n",
    "                  label_suffix='_over_all',\n",
    "                  price_rename='shop_price',\n",
    "                  count_rename='shop_count',\n",
    "                  train_set = 'train',\n",
    "                  test_set = test_set)\n",
    "\n",
    "# Remove the item_id\n",
    "\n",
    "for set_name in ['train', test_set]:\n",
    "    Data[set_name] = Data[set_name].drop(['item_id', 'item_category_id', 'shop_id'], axis = 1)\n",
    "    \n",
    "Data['train'] = Data['train'].drop(['item_shop_price'], axis = 1)\n",
    "if training:\n",
    "    Data['evaluation'] = Data['evaluation'].drop(['item_shop_price'], axis = 1)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorder the columns alphabetically to avoid issues with columns position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    set_list = ['train','evaluation']\n",
    "else:\n",
    "    set_list = ['train','test']\n",
    "\n",
    "for set_name in set_list:\n",
    "    Data[set_name].sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['test'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "case = '20180202b'\n",
    "\n",
    "DATA_LEARNING_FILE = \"../data/sales-\" + case\n",
    "DATA_EVALUATION_FILE = \"../data/evaluation-\" + case\n",
    "DATA_TEST_FILE = \"../data/test-\" + case\n",
    "\n",
    "Data['train'].to_pickle(DATA_LEARNING_FILE)\n",
    "if training:\n",
    "    Data['evaluation'].to_pickle(DATA_EVALUATION_FILE)\n",
    "else:\n",
    "    Data['test'].to_pickle(DATA_TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20180127c : with windsorization 0.999 , removing rows for store, item without any sale\n",
    "# 20180127d : idem without windsorization \n",
    "# 20180127e : idem with windsorization 0.9999\n",
    "# 20180127f : idem with windsorization 0.99\n",
    "# 20180127g : idem with windsorization 0.99, with full set\n",
    "# 20180127h : idem with windsorization 0.999, with full set\n",
    "# 20180128c : windsorization on train only 0.999, with train/eval split\n",
    "# 20180128d : windsorization on train only 0.99, with train/eval split\n",
    "# 20180128e : no windsorization, with train/eval split\n",
    "# 20180128f : with windsor 0.999 on price, with train/eval split\n",
    "# 20180128g : with windsor 0.999 on price, without eval\n",
    "# 201801230a : with windsor 0.999 on price, with eval, with lagged item_count, shop_id, item_category_id\n",
    "# 201801230b : with windsor 0.999 on price, without eval, with lagged item_count, shop_id, item_category_id\n",
    "# 20180201a : with new mean encoding, lagged features, no shop,item, category ids\n",
    "# there was a mistake on the previous set, for the calculation of the item_price_mean_over_all \n",
    "# 20180202a: with proper calculation\n",
    "# 20180202b: to prepare test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart it to retrieve data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "training = True\n",
    "\n",
    "case = '20180202a'\n",
    "\n",
    "DATA_LEARNING_FILE = \"../data/sales-\" + case\n",
    "DATA_EVALUATION_FILE = \"../data/evaluation-\" + case\n",
    "\n",
    "Data = {}\n",
    "\n",
    "Data['train'] = pd.read_pickle(DATA_LEARNING_FILE)\n",
    "if training:\n",
    "    Data['evaluation'] = pd.read_pickle(DATA_EVALUATION_FILE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train/eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipping  = True\n",
    "\n",
    "# Random split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train_set, test_set = train_test_split(Data['train'], test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Remove the first year to decrease training time (and after we will add delayed values)\n",
    "Data['train'] = Data['train'][Data['train'].date_block_num >11].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "x_train = Data['train'].drop(['item_shop_count'], axis = 1)\n",
    "\n",
    "if clipping:\n",
    "    y_train = Data['train'].item_shop_count.clip(0,20)\n",
    "else:\n",
    "    y_train = Data['train'].item_shop_count\n",
    "\n",
    "# I should remove the evaluation prediction rows with missings category\n",
    "\n",
    "if training:\n",
    "    x_eval = Data['evaluation'].drop(['item_shop_count'], axis = 1)\n",
    "    if clipping:\n",
    "        y_eval = Data['evaluation'].item_shop_count.clip(0,20)\n",
    "    else:\n",
    "        y_eval = Data['evaluation'].item_shop_count\n",
    "\n",
    "del(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_eval.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_evaluation(model_reg, x_train, y_train, x_test, y_test, use_average = True): \n",
    "    sales_predictions = model_reg.predict(x_train)\n",
    "    mse = mean_squared_error(y_train, sales_predictions)\n",
    "    rmse_train = np.sqrt(mse)\n",
    "\n",
    "    sales_predictions = pd.DataFrame({'pred': model_reg.predict(x_test)})\n",
    "    \n",
    "    if use_average:\n",
    "        # replace the item rows with no values, with the average on the category for this shop\n",
    "        missing_shop_item_rows =x_test.item_price_mean_over_all == -999\n",
    "        print('Missing lines for shop,items: ', len(x_test[missing_shop_item_rows]))\n",
    "        sales_predictions.loc[missing_shop_item_rows, 'pred'] = x_test[missing_shop_item_rows].category_shop_count_mean_over_months\n",
    "    \n",
    "        # replace the shop, category with no values, with 0 (the shop is not selling this category)\n",
    "        missing_shop_category_rows = sales_predictions.pred == -999  \n",
    "        print('Missing lines for shop,category: ', len(x_test[missing_shop_category_rows]))\n",
    "        sales_predictions.loc[missing_shop_category_rows, 'pred'] = 0\n",
    "    \n",
    "    mse = mean_squared_error(y_test.clip(0,20), sales_predictions.pred.clip(0,20))\n",
    "    rmse_test = np.sqrt(mse)\n",
    "\n",
    "    print(\"train error: \", '{0:.3f}'.format(rmse_train), \"evaluation error: \", '{0:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df_reg = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
    "           max_features=3, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=1,\n",
    "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=150, n_jobs=5, oob_score=False, random_state=None,\n",
    "           verbose=0, warm_start=False)\n",
    "df_reg.fit(x_train.fillna(-999), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_evaluation(df_reg, x_train.fillna(-999), y_train, x_eval.fillna(-999), y_eval, use_average = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_eval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with 20180127c\n",
    "# max_depth=15, n_estimators=20, max_features: 3 : 1.004 / 1.403\n",
    "# max_depth=20, n_estimators=20, max_features: 2 : 0.839 / 1.399\n",
    "# max_depth=20, n_estimators=20, max_features: 3 : 0.818 / 1.394\n",
    "# max_depth=20, n_estimators=50, max_features: 3 : 0.834 / 1.391 > best\n",
    "# max_depth=25, n_estimators=20, max_features: 3 : 0.657 / 1.404\n",
    "# max_depth=20, n_estimators=20, max_features: 4 : 0.795 / 1.410\n",
    "\n",
    "# with 20180127d, max_depth=20, n_estimators=50, max_features: 3\n",
    "# train error: 1.104 evaluation error:  4.596 > windsorization is essential!!\n",
    "\n",
    "# with 20180127e, max_depth=20, n_estimators=25, max_features: 3\n",
    "# train error:  0.949 evaluation error:  1.612 still not as good\n",
    "\n",
    "# with 20180127f, max_depth=20, n_estimators=25, max_features: 3\n",
    "# train error:  0.696 evaluation error:  1.027 > best but beware, \n",
    "#I may just be reducing the variance of the evaluation set :)  \n",
    "# let check with the Kaggle :) \n",
    "# with clip 0-20 train error:  0.692 evaluation error:  0.924 (meaningless as it was windsored)\n",
    "\n",
    "# with 20180127h, max_depth=20, n_estimators=50, max_features: 3, windsor:0.999, full set\n",
    "# kaggle: 1.41\n",
    "\n",
    "# with 20180127g, max_depth=20, n_estimators=50, max_features: 3, windsor:0.99, full set\n",
    "# kaggle: 1.40 > best\n",
    "\n",
    "# Conclusion: we have brought the results much closer 0.7 / 1.0 / 1.4\n",
    "# but we are still higher than before ??? \n",
    "# does the category do help or harm?\n",
    "\n",
    "# with 20180127f, removing category stat, max_depth=20, n_estimators=25, max_features: 3, windsor:0.99, full set\n",
    "# 0.677 evaluation error:  1.043 : slightly worse\n",
    "\n",
    "# with 20180128d, max_depth=20, n_estimators=25, max_features: 3, windsor on train 0.99\n",
    "# train error:  0.601 evaluation error:  5.237\n",
    "# with clipping 0-20: train error:  0.607 evaluation error:  0.979\n",
    "\n",
    "# with 20180128c, max_depth=20, n_estimators=25, max_features: 3, windsor on train 0.999\n",
    "# train error:  0.743 evaluation error:  5.039\n",
    "# with clipping 0-20: train error:  0.743 evaluation error:  0.996\n",
    "\n",
    "# with 20180128e, max_depth=20, n_estimators=25, max_features: 3, no windsor on train\n",
    "# train error:  1.095 evaluation error:  4.702\n",
    "# with clipping 0-20 at evaluation (y_eval and pred): train error:  1.094 evaluation error:  1.002\n",
    "# with clipping 0-20 of y_train train error:  0.616 evaluation error:  0.975 > best\n",
    "\n",
    "# with 20180128f, max_depth=20, n_estimators=25, max_features: 3,  windsor 0.999 on price only, clipping 0-20 on train\n",
    "# train error:  0.616 evaluation error:  0.973 > best\n",
    "\n",
    "# with 20180128g, max_depth=20, n_estimators=100, max_features: 3,  windsor 0.999 on price only, clipping 0-20 on train\n",
    "# no eval\n",
    "# kaggle: 1.02119\n",
    "\n",
    "# with 20180130a, max_depth=20, n_estimators=25, max_features: 3,  with lagged features, item_id, category_item_id\n",
    "# 0.567 evaluation error:  0.962 > overfitted...\n",
    "\n",
    "# with 20180130b, max_depth=20, n_estimators=25, max_features: 3,  with lagged features, without item_id, category_item_id\n",
    "# 0.579 evaluation error:  0.968 > actually slightly worse\n",
    "# Kaggle:\n",
    "\n",
    "# with 20180201a, train error:  0.537 evaluation error:  1.011 > overfit\n",
    "# idem Xgboost eta = 0.3,max_depth=4, n_estimators=300, learning_rate=0.05:  0.876 evaluation error:  0.977\n",
    "\n",
    "# with 20180202a train error:  0.517 evaluation error:  0.994 > overfit \n",
    "# with 20180202a , nmax_depth = 15, n_estimators = 25\n",
    "# train error:  0.641 evaluation error:  0.980 > better\n",
    "# with 20180202a , nmax_depth = 12, n_estimators = 25\n",
    "# train error:  0.711 evaluation error:  0.978\n",
    "# with 20180202a , nmax_depth = 10, n_estimators = 25\n",
    "# train error:  0.739 evaluation error:  0.977 (without use_average)\n",
    "# train error:  0.739 evaluation error:  0.956 (with use_average) >> best\n",
    "\n",
    "# 20180202b: kaggle: 0.99725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(df_reg, '../models/randomforest_20180128g.pkl')\n",
    "#df_reg = joblib.load('../models/randomforest_20180127g.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = df_reg.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=5, n_iter=None, penalty='l2',\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "ln_reg = SGDRegressor(\n",
    "    penalty='l2'\n",
    ")\n",
    "\n",
    "ln_reg.fit(x_train.fillna(0), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing lines for shop,items:  0\n",
      "Missing lines for shop,category:  0\n",
      "train error:  7058554053649491.000 evaluation error:  10.487\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(ln_reg, x_train.fillna(0), y_train, x_eval.fillna(0), y_eval, use_average = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# You can experiment with many other options here, using the same .fit() and .predict()\n",
    "# methods; see http://scikit-learn.org\n",
    "# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\n",
    "\n",
    "\n",
    "# replace the shop, item rows with no values, with the average on the category \n",
    "missing_item_rows = pd.isnull(x_eval.item_price_mean_over_all)\n",
    "\n",
    "def clipped_rmse(preds, deval):  \n",
    "\n",
    "    sales_predictions = pd.DataFrame({'pred': preds})\n",
    "    sales_predictions.loc[missing_item_rows, 'pred'] = x_eval[missing_item_rows].category_shop_count_mean_over_months\n",
    "    sales_predictions.loc[pd.isnull(sales_predictions.pred), 'pred'] = 0\n",
    "\n",
    "    score = np.sqrt(mean_squared_error(y_eval.clip(0,20), sales_predictions.pred.clip(0,20)))\n",
    "    return 'clipped_rmse', score\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.fillna(-999).values, label=y_train.values, missing=-999)\n",
    "dtest = xgb.DMatrix(x_eval.fillna(-999).values, label=y_eval.values, missing=-999)\n",
    "evallist = [(dtest, 'eval')]\n",
    "\n",
    "# specify parameters via map\n",
    "param = {'max_depth':15,\n",
    "         'min_child_weight': 5,\n",
    "         'eta':0.02,\n",
    "         'silent':0}\n",
    "\n",
    "num_round= 100\n",
    "\n",
    "gbm = xgb.train(param, dtrain, num_round, evallist, feval=clipped_rmse, early_stopping_rounds=20,  maximize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_predictions = pd.DataFrame({'pred': gbm.predict(dtest, ntree_limit=gbm.best_ntree_limit)})\n",
    "    \n",
    "# replace the item rows with no values, with the average on the category for the shop\n",
    "missing_shop_item_rows = pd.isnull(x_eval.item_price_mean_over_all)\n",
    "print('Missing lines for items: ', len(x_eval[missing_shop_item_rows]))\n",
    "sales_predictions.loc[missing_shop_item_rows, 'pred'] = x_eval[missing_shop_item_rows].category_shop_count_mean_over_months\n",
    "\n",
    "# replace the shop, category with no values, with 0 (the shop is not selling this category)\n",
    "missing_shop_category_rows = pd.isnull(sales_predictions.pred)\n",
    "print('Missing lines for shop,category: ', len(x_eval[missing_shop_category_rows]))\n",
    "sales_predictions.loc[missing_shop_category_rows, 'pred'] = 0\n",
    "\n",
    "mse = mean_squared_error(y_eval.clip(0,20), sales_predictions.pred.clip(0,20))\n",
    "rmse_eval = np.sqrt(mse)\n",
    "\n",
    "print(\"evaluation error: \", '{0:.3f}'.format(rmse_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_eval.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [10,50, 100], 'max_features': [2,4,6], 'max_depth': [5, 10, 20]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, n_jobs = 4,\n",
    "                          scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_evaluation(grid_search.best_estimator_, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt_reg = GradientBoostingRegressor(learning_rate = 0.1)\n",
    "gbrt_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_test =  test_set.drop(['item_cnt_month'], axis = 1)\n",
    "y_test = test_set.item_cnt_month\n",
    "\n",
    "model_evaluation(gbrt_reg, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Submission preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_TEST_FILE = \"../data/test-20180202b\"\n",
    "\n",
    "Data = {}\n",
    "\n",
    "Data['test'] = pd.read_pickle(DATA_TEST_FILE)\n",
    "\n",
    "#Data['test'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_average = True\n",
    "\n",
    "X_test = Data['test'].drop(['ID'], axis = 1)\n",
    "\n",
    "# Option 1\n",
    "# It trust the model will learn from the category count for the missing item - \n",
    "# for the missing category, I set the prediction to 0\n",
    "# missing_shop_item_indices = pd.isnull(Data['test']['item_cnt_month_mean'])\n",
    "# This is not improving the score!\n",
    "\n",
    "predictions = pd.DataFrame({'pred': df_reg.predict(X_test.fillna(-999)).clip(0,20)})\n",
    "\n",
    "# replace the shop, item rows with no values, with the average on the category\n",
    "\n",
    "if use_average:\n",
    "        # replace the shop, item rows with no values, with the average on the category \n",
    "        missing_item_rows = pd.isnull(X_test.item_price_mean_over_all)\n",
    "        print('Missing lines for items: ', len(X_test[missing_item_rows]))\n",
    "        predictions.loc[missing_item_rows, 'pred'] = X_test[missing_item_rows].category_shop_count_mean_over_months\n",
    "\n",
    "# for the shop with not category, replace with \n",
    "\n",
    "missing_shop_category_rows = pd.isnull(predictions.pred)\n",
    "print('Missing lines for shop,category: ', len(X_test[missing_shop_category_rows]))\n",
    "predictions.loc[missing_shop_category_rows, 'pred'] = 0\n",
    "\n",
    "# Create the submission file:\n",
    "\n",
    "submission = data_load['sample_submission'].copy()\n",
    "\n",
    "submission.loc[:, 'item_cnt_month'] = predictions.pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBMISSION_FILE = \"../data/sales_sub_20180202b.csv\"\n",
    "\n",
    "submission.to_csv(SUBMISSION_FILE, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
