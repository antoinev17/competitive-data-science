{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import inspect\n",
    "import os\n",
    "import numpy as np\n",
    "dirname = os.path.dirname(os.path.abspath(inspect.stack()[0][1]))\n",
    "\n",
    "TRAIN_DATA_PATH = \"data/train.csv\"\n",
    "TEST_DATA_PATH = \"data/test.csv\"\n",
    "is_test = True\n",
    "\n",
    "def load_rain_data(data_path=TRAIN_DATA_PATH):\n",
    "    data_path = os.path.join(dirname, data_path)\n",
    "    return pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract training and test sets from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train data\n",
      "1180945  samples\n",
      "Extracting test data\n",
      "717625  samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting train data\")\n",
    "rain_train = load_rain_data(TRAIN_DATA_PATH)\n",
    "\n",
    "n_total_samples_train = len(rain_train.groupby('Id'))\n",
    "print(n_total_samples_train, \" samples\")\n",
    "\n",
    "print(\"Extracting test data\")\n",
    "rain_test = load_rain_data(TEST_DATA_PATH)\n",
    "\n",
    "n_total_samples_test = len(rain_test.groupby('Id'))\n",
    "print(n_total_samples_test, \" samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the median of Expected value for the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median value training set: 1.0160005\n"
     ]
    }
   ],
   "source": [
    "median_expected = np.median(rain_train['Expected'])\n",
    "print (\"Median value training set:\", median_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the physical features for partial missing values per series, and  add a new column to each physical measure to keep the fact that there was a missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column  Id  Removing the partial N/A\n",
      "Column  minutes_past  Removing the partial N/A\n",
      "Column  radardist_km  Removing the partial N/A\n",
      "Column  Ref  Removing the partial N/A\n",
      "Column  Ref_5x5_10th  Removing the partial N/A\n",
      "Column  Ref_5x5_50th  Removing the partial N/A\n",
      "Column  Ref_5x5_90th  Removing the partial N/A\n",
      "Column  RefComposite  Removing the partial N/A\n",
      "Column  RefComposite_5x5_10th  Removing the partial N/A\n",
      "Column  RefComposite_5x5_50th  Removing the partial N/A\n",
      "Column  RefComposite_5x5_90th  Removing the partial N/A\n",
      "Column  RhoHV  Removing the partial N/A\n",
      "Column  RhoHV_5x5_10th  Removing the partial N/A\n",
      "Column  RhoHV_5x5_50th  Removing the partial N/A\n",
      "Column  RhoHV_5x5_90th  Removing the partial N/A\n",
      "Column  Zdr  Removing the partial N/A\n",
      "Column  Zdr_5x5_10th  Removing the partial N/A\n",
      "Column  Zdr_5x5_50th  Removing the partial N/A\n",
      "Column  Zdr_5x5_90th  Removing the partial N/A\n",
      "Column  Kdp  Removing the partial N/A\n",
      "Column  Kdp_5x5_10th  Removing the partial N/A\n",
      "Column  Kdp_5x5_50th  Removing the partial N/A\n",
      "Column  Kdp_5x5_90th  Removing the partial N/A\n"
     ]
    }
   ],
   "source": [
    "column_start = ('Ref', 'Kdp', 'Zdr', 'Rho')\n",
    "\n",
    "for column in rain_test.columns:\n",
    "    \n",
    "    # Create new columns to keep the information that values were missing\n",
    "    if column.startswith(column_start):\n",
    "        rain_train[column + \"_NA\"] = pd.Series(rain_train[column].isnull(), index=rain_train.index)\n",
    "        rain_test[column + \"_NA\"] = pd.Series(rain_test[column].isnull(), index=rain_test.index)\n",
    "    \n",
    "    # Filling the missing value on a series with the mean of other sample of the same series\n",
    "    print(\"Column \",column, \" Removing the partial N/A\")\n",
    "    rain_train[column].fillna(rain_train.groupby(['Id'])[column].transform(\"mean\"), inplace=True)\n",
    "    rain_test[column].fillna(rain_test.groupby(['Id'])[column].transform(\"mean\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the lines with no values at all or with expected value bigger than a resonable value (730 mm per hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples removed from training set: 363237\n",
      "Number of samples removed from test set: 232148\n",
      "Removing the N/A\n",
      "Training set: correct operation\n",
      "Test set: correct operation\n"
     ]
    }
   ],
   "source": [
    "wrong_values_train = (pd.DataFrame(rain_train.isnull().sum(axis=1))[0]==20) | (rain_train['Expected']  > 730)\n",
    "wrong_values_test = (pd.DataFrame(rain_test.isnull().sum(axis=1))[0]==20)\n",
    "\n",
    "# Saving the sample indices that are considered useless\n",
    "\n",
    "wrong_indices_train = rain_train[wrong_values_train].groupby('Id')['Id'].first().as_matrix()\n",
    "print(\"Number of samples removed from training set:\", len(wrong_indices_train))\n",
    "wrong_indices_test = rain_test[wrong_values_test].groupby('Id')['Id'].first().as_matrix()\n",
    "print(\"Number of samples removed from test set:\", len(wrong_indices_test))\n",
    "\n",
    "# Remove the wrong values rows from training and testing set\n",
    "\n",
    "rain_train.drop(rain_train.index[wrong_values_train], inplace = True)\n",
    "rain_test.drop(rain_test.index[wrong_values_test], inplace = True)\n",
    "\n",
    "# Replace the missing values in the remaining samples with average features\n",
    "\n",
    "print(\"Removing the N/A\")\n",
    "rain_train.fillna(rain_train.mean(), inplace=True)\n",
    "rain_test.fillna(rain_test.mean(), inplace=True)\n",
    "\n",
    "# Check that the sample were correctly split between wrong indices and correct indices\n",
    "if (n_total_samples_train == len(rain_train.groupby('Id')) + len(wrong_indices_train)):\n",
    "    print(\"Training set: correct operation\")\n",
    "\n",
    "if (n_total_samples_test == len(rain_test.groupby('Id')) + len(wrong_indices_test)):\n",
    "    print(\"Test set: correct operation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>minutes_past</th>\n",
       "      <th>radardist_km</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Ref_5x5_10th</th>\n",
       "      <th>Ref_5x5_50th</th>\n",
       "      <th>Ref_5x5_90th</th>\n",
       "      <th>RefComposite</th>\n",
       "      <th>RefComposite_5x5_10th</th>\n",
       "      <th>RefComposite_5x5_50th</th>\n",
       "      <th>...</th>\n",
       "      <th>RhoHV_5x5_90th</th>\n",
       "      <th>Zdr</th>\n",
       "      <th>Zdr_5x5_10th</th>\n",
       "      <th>Zdr_5x5_50th</th>\n",
       "      <th>Zdr_5x5_90th</th>\n",
       "      <th>Kdp</th>\n",
       "      <th>Kdp_5x5_10th</th>\n",
       "      <th>Kdp_5x5_50th</th>\n",
       "      <th>Kdp_5x5_90th</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "      <td>1.014760e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.925405e+05</td>\n",
       "      <td>2.953674e+01</td>\n",
       "      <td>1.002512e+01</td>\n",
       "      <td>2.164839e+01</td>\n",
       "      <td>1.872079e+01</td>\n",
       "      <td>2.142921e+01</td>\n",
       "      <td>2.452981e+01</td>\n",
       "      <td>2.319889e+01</td>\n",
       "      <td>2.071512e+01</td>\n",
       "      <td>2.304135e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015786e+00</td>\n",
       "      <td>5.967037e-01</td>\n",
       "      <td>-8.102434e-01</td>\n",
       "      <td>2.171537e-01</td>\n",
       "      <td>2.008086e+00</td>\n",
       "      <td>5.661480e-02</td>\n",
       "      <td>-3.723776e+00</td>\n",
       "      <td>-8.694066e-01</td>\n",
       "      <td>3.839131e+00</td>\n",
       "      <td>8.490970e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.407383e+05</td>\n",
       "      <td>1.730655e+01</td>\n",
       "      <td>4.013964e+00</td>\n",
       "      <td>9.261549e+00</td>\n",
       "      <td>7.620667e+00</td>\n",
       "      <td>8.930816e+00</td>\n",
       "      <td>1.066492e+01</td>\n",
       "      <td>9.768875e+00</td>\n",
       "      <td>8.233327e+00</td>\n",
       "      <td>9.446000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.890237e-02</td>\n",
       "      <td>1.265262e+00</td>\n",
       "      <td>7.679890e-01</td>\n",
       "      <td>7.833905e-01</td>\n",
       "      <td>1.446703e+00</td>\n",
       "      <td>3.205379e+00</td>\n",
       "      <td>2.140965e+00</td>\n",
       "      <td>2.036347e+00</td>\n",
       "      <td>3.690846e+00</td>\n",
       "      <td>4.648318e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.100000e+01</td>\n",
       "      <td>-3.200000e+01</td>\n",
       "      <td>-3.200000e+01</td>\n",
       "      <td>-2.850000e+01</td>\n",
       "      <td>-3.200000e+01</td>\n",
       "      <td>-3.100000e+01</td>\n",
       "      <td>-2.750000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.083333e-01</td>\n",
       "      <td>-7.875000e+00</td>\n",
       "      <td>-7.875000e+00</td>\n",
       "      <td>-7.875000e+00</td>\n",
       "      <td>-7.875000e+00</td>\n",
       "      <td>-9.604000e+01</td>\n",
       "      <td>-8.079000e+01</td>\n",
       "      <td>-7.877000e+01</td>\n",
       "      <td>-1.002000e+02</td>\n",
       "      <td>1.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.960520e+05</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.590000e+01</td>\n",
       "      <td>1.466667e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.675000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.987500e-01</td>\n",
       "      <td>9.375000e-02</td>\n",
       "      <td>-8.750000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.250000e+00</td>\n",
       "      <td>-5.250015e-01</td>\n",
       "      <td>-3.723776e+00</td>\n",
       "      <td>-8.694066e-01</td>\n",
       "      <td>2.470001e+00</td>\n",
       "      <td>2.540001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.931650e+05</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.164839e+01</td>\n",
       "      <td>1.872079e+01</td>\n",
       "      <td>2.142921e+01</td>\n",
       "      <td>2.450000e+01</td>\n",
       "      <td>2.319889e+01</td>\n",
       "      <td>2.071512e+01</td>\n",
       "      <td>2.304135e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015786e+00</td>\n",
       "      <td>5.967037e-01</td>\n",
       "      <td>-8.102434e-01</td>\n",
       "      <td>2.171537e-01</td>\n",
       "      <td>2.008086e+00</td>\n",
       "      <td>5.661480e-02</td>\n",
       "      <td>-3.723776e+00</td>\n",
       "      <td>-8.694066e-01</td>\n",
       "      <td>3.839131e+00</td>\n",
       "      <td>1.016000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.907310e+05</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>2.675000e+01</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>2.650000e+01</td>\n",
       "      <td>3.150000e+01</td>\n",
       "      <td>2.868750e+01</td>\n",
       "      <td>2.450000e+01</td>\n",
       "      <td>2.850000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051667e+00</td>\n",
       "      <td>8.125000e-01</td>\n",
       "      <td>-5.625000e-01</td>\n",
       "      <td>3.750000e-01</td>\n",
       "      <td>2.303571e+00</td>\n",
       "      <td>6.999969e-01</td>\n",
       "      <td>-2.820007e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.580002e+00</td>\n",
       "      <td>3.302002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.180945e+06</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>6.250000e+01</td>\n",
       "      <td>6.900000e+01</td>\n",
       "      <td>7.250000e+01</td>\n",
       "      <td>9.250000e+01</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051667e+00</td>\n",
       "      <td>7.937500e+00</td>\n",
       "      <td>7.937500e+00</td>\n",
       "      <td>7.937500e+00</td>\n",
       "      <td>7.937500e+00</td>\n",
       "      <td>1.797500e+02</td>\n",
       "      <td>3.519989e+00</td>\n",
       "      <td>1.280000e+01</td>\n",
       "      <td>1.446000e+02</td>\n",
       "      <td>9.939025e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id  minutes_past  radardist_km           Ref  Ref_5x5_10th  \\\n",
       "count  1.014760e+07  1.014760e+07  1.014760e+07  1.014760e+07  1.014760e+07   \n",
       "mean   5.925405e+05  2.953674e+01  1.002512e+01  2.164839e+01  1.872079e+01   \n",
       "std    3.407383e+05  1.730655e+01  4.013964e+00  9.261549e+00  7.620667e+00   \n",
       "min    2.000000e+00  0.000000e+00  0.000000e+00 -3.100000e+01 -3.200000e+01   \n",
       "25%    2.960520e+05  1.500000e+01  7.000000e+00  1.590000e+01  1.466667e+01   \n",
       "50%    5.931650e+05  3.000000e+01  1.000000e+01  2.164839e+01  1.872079e+01   \n",
       "75%    8.907310e+05  4.400000e+01  1.300000e+01  2.675000e+01  2.200000e+01   \n",
       "max    1.180945e+06  5.900000e+01  2.100000e+01  7.100000e+01  6.250000e+01   \n",
       "\n",
       "       Ref_5x5_50th  Ref_5x5_90th  RefComposite  RefComposite_5x5_10th  \\\n",
       "count  1.014760e+07  1.014760e+07  1.014760e+07           1.014760e+07   \n",
       "mean   2.142921e+01  2.452981e+01  2.319889e+01           2.071512e+01   \n",
       "std    8.930816e+00  1.066492e+01  9.768875e+00           8.233327e+00   \n",
       "min   -3.200000e+01 -2.850000e+01 -3.200000e+01          -3.100000e+01   \n",
       "25%    1.600000e+01  1.700000e+01  1.675000e+01           1.600000e+01   \n",
       "50%    2.142921e+01  2.450000e+01  2.319889e+01           2.071512e+01   \n",
       "75%    2.650000e+01  3.150000e+01  2.868750e+01           2.450000e+01   \n",
       "max    6.900000e+01  7.250000e+01  9.250000e+01           6.600000e+01   \n",
       "\n",
       "       RefComposite_5x5_50th      ...       RhoHV_5x5_90th           Zdr  \\\n",
       "count           1.014760e+07      ...         1.014760e+07  1.014760e+07   \n",
       "mean            2.304135e+01      ...         1.015786e+00  5.967037e-01   \n",
       "std             9.446000e+00      ...         4.890237e-02  1.265262e+00   \n",
       "min            -2.750000e+01      ...         2.083333e-01 -7.875000e+00   \n",
       "25%             1.700000e+01      ...         9.987500e-01  9.375000e-02   \n",
       "50%             2.304135e+01      ...         1.015786e+00  5.967037e-01   \n",
       "75%             2.850000e+01      ...         1.051667e+00  8.125000e-01   \n",
       "max             7.100000e+01      ...         1.051667e+00  7.937500e+00   \n",
       "\n",
       "       Zdr_5x5_10th  Zdr_5x5_50th  Zdr_5x5_90th           Kdp  Kdp_5x5_10th  \\\n",
       "count  1.014760e+07  1.014760e+07  1.014760e+07  1.014760e+07  1.014760e+07   \n",
       "mean  -8.102434e-01  2.171537e-01  2.008086e+00  5.661480e-02 -3.723776e+00   \n",
       "std    7.679890e-01  7.833905e-01  1.446703e+00  3.205379e+00  2.140965e+00   \n",
       "min   -7.875000e+00 -7.875000e+00 -7.875000e+00 -9.604000e+01 -8.079000e+01   \n",
       "25%   -8.750000e-01  0.000000e+00  1.250000e+00 -5.250015e-01 -3.723776e+00   \n",
       "50%   -8.102434e-01  2.171537e-01  2.008086e+00  5.661480e-02 -3.723776e+00   \n",
       "75%   -5.625000e-01  3.750000e-01  2.303571e+00  6.999969e-01 -2.820007e+00   \n",
       "max    7.937500e+00  7.937500e+00  7.937500e+00  1.797500e+02  3.519989e+00   \n",
       "\n",
       "       Kdp_5x5_50th  Kdp_5x5_90th      Expected  \n",
       "count  1.014760e+07  1.014760e+07  1.014760e+07  \n",
       "mean  -8.694066e-01  3.839131e+00  8.490970e+00  \n",
       "std    2.036347e+00  3.690846e+00  4.648318e+01  \n",
       "min   -7.877000e+01 -1.002000e+02  1.000000e-02  \n",
       "25%   -8.694066e-01  2.470001e+00  2.540001e-01  \n",
       "50%   -8.694066e-01  3.839131e+00  1.016000e+00  \n",
       "75%    0.000000e+00  4.580002e+00  3.302002e+00  \n",
       "max    1.280000e+01  1.446000e+02  9.939025e+02  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data by regrouping measurements with the same id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the dimensions of cleaned sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of steps:  19\n",
      "Number of samples 817708 485477\n",
      "Number of inputs:  42\n"
     ]
    }
   ],
   "source": [
    "#We have to make the assumption that the test set has no more steps than the training set\n",
    "n_steps = rain_train.groupby(['Id']).size().max()\n",
    "n_samples_train = rain_train.groupby(['Id']).size().shape[0]\n",
    "n_samples_test = rain_test.groupby(['Id']).size().shape[0]\n",
    "\n",
    "# Number of features, not counting the Id column\n",
    "n_inputs = len(rain_test.columns) - 1     \n",
    "  \n",
    "print(\"Max number of steps: \", n_steps)\n",
    "print(\"Number of samples\", n_samples_train, n_samples_test)\n",
    "print(\"Number of inputs: \", n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 3D data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_train = rain_train.groupby(['Id'])['Id'].first().as_matrix()\n",
    "indices_test = rain_test.groupby(['Id'])['Id'].first().as_matrix()\n",
    "\n",
    "y_train = rain_train.groupby(['Id'])['Expected'].first().as_matrix()\n",
    "rain_train.drop(['Expected'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the training set...\n",
      "Treating - step:  0\n",
      "Treating - step:  100000\n",
      "Treating - step:  200000\n",
      "Treating - step:  300000\n",
      "Treating - step:  400000\n",
      "Treating - step:  500000\n",
      "Treating - step:  600000\n",
      "Treating - step:  700000\n",
      "Treating - step:  800000\n"
     ]
    }
   ],
   "source": [
    "# For each sample, create a plane n_steps * n_inputs and padded with 0\n",
    "\n",
    "seq_length_train = np.zeros(n_samples_train)\n",
    "\n",
    "X_train = np.zeros((n_samples_train, n_steps, n_inputs))\n",
    "\n",
    "# Treating the training set\n",
    "print(\"Creating the training set...\")\n",
    "\n",
    "i=0\n",
    "for name, group in rain_train.groupby(['Id']):\n",
    "    \n",
    "    # Seems useless are data is already sorted\n",
    "    #group.sort_values(by=['minutes_past'], inplace = True)\n",
    "    \n",
    "    # Remove the Id Column\n",
    "    A_train = group.drop('Id', axis=1).as_matrix()\n",
    "    \n",
    "    # Extract the number of rows for this sample: sequence length\n",
    "    seq_length_train[i] = A_train.shape[0]\n",
    "    # Padding with 0 to complete the sequence \n",
    "    X_train[i,:,:] = np.pad(A_train, ((0, n_steps - A_train.shape[0]), (0,0)), 'constant')\n",
    "\n",
    "    if (i%100000==0):\n",
    "        print(\"Treating - step: \",i)\n",
    "    i = i+1\n",
    "    \n",
    "del rain_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the test set...\n",
      "Treating - step:  0\n",
      "Treating - step:  100000\n",
      "Treating - step:  200000\n",
      "Treating - step:  300000\n",
      "Treating - step:  400000\n"
     ]
    }
   ],
   "source": [
    "X_test = np.zeros((n_samples_test, n_steps, n_inputs))\n",
    "seq_length_test = np.zeros(n_samples_test)\n",
    "\n",
    "# Treating the test set\n",
    "print(\"Creating the test set...\")\n",
    "\n",
    "i=0\n",
    "for name, group in rain_test.groupby(['Id']):\n",
    "\n",
    "    # Seems useless are data is already sorted\n",
    "    #group.sort_values(by=['minutes_past'], inplace = True)\n",
    "\n",
    "    # Remove the Id Column\n",
    "    A_test = group.drop('Id', axis=1).as_matrix()\n",
    "        \n",
    "    # Extract the sequence length\n",
    "    seq_length_test[i] = A_test.shape[0]\n",
    "    \n",
    "    # Padding with 0 to complete the sequence\n",
    "    X_test[i,:,:] = np.pad(A_test, ((0, n_steps - A_test.shape[0]), (0,0)), 'constant')\n",
    "\n",
    "    if (i%100000==0):\n",
    "        print(\"Treating - step: \",i)\n",
    "    i = i+1\n",
    "    \n",
    "del rain_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training set into train and eval sets and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_ratio = 0.2\n",
    "shuffled_idx = np.random.permutation(n_samples_train)\n",
    "train_size = int(n_samples_train * (1 - eval_ratio))\n",
    "\n",
    "np.save(\"WIR2-X-train-7.npy\", X_train[shuffled_idx[:train_size]])\n",
    "np.save(\"WIR2-y-train-7.npy\", y_train[shuffled_idx[:train_size]])\n",
    "np.save(\"WIR2-indices-train-7.npy\", indices_train[shuffled_idx[:train_size]])\n",
    "np.save(\"WIR2-seq_length-train-7.npy\", seq_length_train[shuffled_idx[:train_size]])\n",
    "\n",
    "np.save(\"WIR2-X-eval-7.npy\", X_train[shuffled_idx[train_size:]])\n",
    "np.save(\"WIR2-y-eval-7.npy\", y_train[shuffled_idx[train_size:]])\n",
    "np.save(\"WIR2-indices-eval-7.npy\", indices_train[shuffled_idx[train_size:]])\n",
    "np.save(\"WIR2-seq_length-eval-7.npy\", seq_length_train[shuffled_idx[train_size:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the test set\n",
    "\n",
    "np.save(\"WIR2-X-test-7.npy\", X_test)\n",
    "np.save(\"WIR2-indices-test-7.npy\", indices_test)\n",
    "np.save(\"WIR2-seq_length-test-7.npy\", seq_length_test)\n",
    "np.save(\"WIR2-wrong_indices-test-7.npy\", wrong_indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-cpu]",
   "language": "python",
   "name": "conda-env-tensorflow-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
