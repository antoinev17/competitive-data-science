{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data prepared with Data preparation sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  654166\n",
      "Number of eval samples:  163542\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"WIR2-X-train-7.npy\")\n",
    "y_train = np.load(\"WIR2-y-train-7.npy\").reshape(len(X_train),1)\n",
    "indices_train = np.load(\"WIR2-indices-train-7.npy\")\n",
    "seq_length_train = np.load(\"WIR2-seq_length-train-7.npy\")\n",
    "\n",
    "X_eval = np.load(\"WIR2-X-eval-7.npy\")\n",
    "y_eval= np.load(\"WIR2-y-eval-7.npy\").reshape(len(X_eval),1)\n",
    "indices_eval = np.load(\"WIR2-indices-eval-7.npy\")\n",
    "seq_length_eval = np.load(\"WIR2-seq_length-eval-7.npy\")\n",
    "\n",
    "print(\"Number of train samples: \", len(X_train))\n",
    "print(\"Number of eval samples: \", len(X_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the recurrent neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.layers import dropout\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_steps, n_features = X_train.shape[1], X_train.shape[2]\n",
    "n_neurons = 400\n",
    "learning_rate = 0.02\n",
    "keep_prob = 0.5\n",
    "n_layers = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_steps, n_features], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape = [None,1], name = \"y\")\n",
    "is_training = tf.placeholder_with_default(False, shape=[])\n",
    "seq_length = tf.placeholder(tf.int32, shape = [None])\n",
    "\n",
    "# Using alternative cells: GRU Cell or basic cell\n",
    "#gru_cell_1 = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation = tf.nn.relu)\n",
    "#gru_cell_2 = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation = tf.nn.relu)\n",
    "#multi_layer_cell = tf.contrib.rnn.MultiRNNCell([gru_cell_1, gru_cell_2])\n",
    "\n",
    "#basic_cell_1 = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation = tf.nn.relu)\n",
    "#basic_cell_2 = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation = tf.nn.relu)\n",
    "\n",
    "# Using STM cell\n",
    "improved_STM_cell_1 = tf.contrib.rnn.LayerNormBasicLSTMCell(num_units=n_neurons, activation = tf.nn.relu, dropout_keep_prob = 0.5)\n",
    "improved_STM_cell_2 = tf.contrib.rnn.LayerNormBasicLSTMCell(num_units=n_neurons, activation = tf.nn.relu, dropout_keep_prob = 0.5)\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell([improved_STM_cell_1, improved_STM_cell_2], state_is_tuple = True)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype= tf.float32, sequence_length=seq_length)\n",
    "\n",
    "#Last layer states, consireding there are 2 layers\n",
    "last_states = states[1]\n",
    "\n",
    "#Last relevant output: for a LSTM, states is a tuple (c, h) where c is the last state and h the last output\n",
    "last_output = last_states[1]\n",
    "\n",
    "#last_output = last_states\n",
    "\n",
    "# Dropout before fully connected layer\n",
    "output_drop = dropout(last_output, keep_prob, is_training=is_training ) \n",
    "\n",
    "# Single neuron output: 'Expected' prediction\n",
    "prediction = fully_connected(output_drop, 1, activation_fn=None)\n",
    "\n",
    "# Calculate the absolute error\n",
    "vector_error = tf.abs(prediction-y)\n",
    "\n",
    "error = tf.reduce_mean(vector_error)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(error)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Epoch:  0 step:  0  Eval error: 11.4319479861\n",
      "Evaluating...\n",
      "Epoch:  0 step:  100000  Eval error: 7.24020764543\n",
      "Evaluating...\n",
      "Epoch:  0 step:  200000  Eval error: 7.22178762439\n",
      "Evaluating...\n",
      "Epoch:  0 step:  300000  Eval error: 7.17070942122\n",
      "Evaluating...\n",
      "Epoch:  0 step:  400000  Eval error: 7.19021157141\n",
      "Evaluating...\n",
      "Epoch:  0 step:  500000  Eval error: 7.11182463223\n",
      "Evaluating...\n",
      "Epoch:  0 step:  600000  Eval error: 7.12102944025\n",
      "Evaluating...\n",
      "Epoch:  1 step:  0  Eval error: 7.11434722274\n",
      "Evaluating...\n",
      "Epoch:  1 step:  100000  Eval error: 7.09075976615\n",
      "Evaluating...\n",
      "Epoch:  1 step:  200000  Eval error: 7.10758454773\n",
      "Evaluating...\n",
      "Epoch:  1 step:  300000  Eval error: 7.08634629195\n",
      "Evaluating...\n",
      "Epoch:  1 step:  400000  Eval error: 7.08532335739\n",
      "Evaluating...\n",
      "Epoch:  1 step:  500000  Eval error: 7.07933107544\n",
      "Evaluating...\n",
      "Epoch:  1 step:  600000  Eval error: 7.06820142117\n",
      "Evaluating...\n",
      "Epoch:  2 step:  0  Eval error: 7.08618465906\n",
      "Evaluating...\n",
      "Epoch:  2 step:  100000  Eval error: 7.1010897318\n",
      "Evaluating...\n",
      "Epoch:  2 step:  200000  Eval error: 7.06549221005\n",
      "Evaluating...\n",
      "Epoch:  2 step:  300000  Eval error: 7.07976908311\n",
      "Evaluating...\n",
      "Epoch:  2 step:  400000  Eval error: 7.05958584726\n",
      "Evaluating...\n",
      "Epoch:  2 step:  500000  Eval error: 7.0575111745\n",
      "Evaluating...\n",
      "Epoch:  2 step:  600000  Eval error: 7.08039553857\n",
      "Evaluating...\n",
      "Epoch:  3 step:  0  Eval error: 7.05598336816\n",
      "Evaluating...\n",
      "Epoch:  3 step:  100000  Eval error: 7.04943738902\n",
      "Evaluating...\n",
      "Epoch:  3 step:  200000  Eval error: 7.05267058397\n",
      "Evaluating...\n",
      "Epoch:  3 step:  300000  Eval error: 7.05806933476\n",
      "Evaluating...\n",
      "Epoch:  3 step:  400000  Eval error: 7.06022929919\n",
      "Evaluating...\n",
      "Epoch:  3 step:  500000  Eval error: 7.07898927071\n",
      "Evaluating...\n",
      "Epoch:  3 step:  600000  Eval error: 7.09202910923\n",
      "Evaluating...\n",
      "Epoch:  4 step:  0  Eval error: 7.09585358779\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_rnn_WIR2_2LNLSTM_400.ckpt\n",
      "Final eval error: 7.049\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 1000\n",
    "SAVE_FILE = \"./my_rnn_WIR2_2LNLSTM_400.ckpt\"\n",
    "\n",
    "train_errors = np.zeros((len(X_train),1))\n",
    "eval_errors = np.zeros((len(X_eval),1))\n",
    "best_error = np.infty\n",
    "checks_without_progress = 0\n",
    "max_checks_without_progress = 5\n",
    "stopping = False\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    # Restore the last version of the network\n",
    "    saver.restore(sess, SAVE_FILE)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        i=0\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch, y_batch, seq_length_batch = X_train[rnd_indices], y_train[rnd_indices], seq_length_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, seq_length: seq_length_batch, is_training: True})\n",
    "            if (i%100 == 0): \n",
    "\n",
    "                # Evaluation of the result for each stop\n",
    "                print('Evaluating...')\n",
    "\n",
    "                # Evaluation on the full eval set\n",
    "                for indices in np.array_split(range(len(X_eval)), len(X_eval) // (batch_size*5)):\n",
    "                    X_batch, y_batch, seq_length_batch = X_eval[indices], y_eval[indices], seq_length_eval[indices]\n",
    "                    eval_errors[indices] = vector_error.eval(feed_dict={X: X_batch, y: y_batch, seq_length: seq_length_batch, is_training: False})            \n",
    "                eval_error = np.mean(eval_errors)\n",
    "\n",
    "                print(\"Epoch: \", epoch, \"step: \",i*batch_size, \" Eval error:\", eval_error)\n",
    "                \n",
    "                if eval_error < best_error:\n",
    "                    #Saving the last version of the network\n",
    "                    checks_without_progress = 0\n",
    "                    save_path = saver.save(sess, SAVE_FILE)\n",
    "                    best_error = eval_error\n",
    "\n",
    "                else: \n",
    "                    checks_without_progress += 1\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        stopping = True\n",
    "                        break\n",
    "                        \n",
    "            i += 1\n",
    "        if stopping: \n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, SAVE_FILE)\n",
    "    print(\"Final eval error: {:.3f}\".format(best_error))               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "improved SLTM, 2 layers, 50 neurons, WIR2-X-3.npy, batch:5000,  Train error: 6.385  Test error: 6.917 > could not save this config\n",
    "\n",
    "improved SLTM, 2 layers, 200 neurons, WIR2-X-3.npy, my_rnn_WIR2-3.ckpt, batch:2500, \n",
    "\n",
    "improved SLTM, 2 layers, 100 neurons, my_rnn_WIR2_2LNLSTM_100n.ckpt, batch:2500, lr:0.005, eval error: 3.46 (but the samples were mixed) > overfitting\n",
    "\n",
    "2017/11/22: improved SLTM, 2 layers, 25 neurons, my_rnn_WIR2_2LNLSTM_100n.ckpt, batch:10000, lr:0.01, eval error: 10\n",
    "\n",
    "2017/11/24: improved SLTM, 2 layers, 50 neurons, my_rnn_WIR2_2LNLSTM_50n.ckpt, batch:10000, lr:0.005 (too low), na lines removed,  eval error: 7.82 > rank: 67e on Kaggle\n",
    "\n",
    "2017/11/24: improved SLTM, 2 layers, 200 neurons, my_rnn_WIR2_2LNLSTM_200n_b, batch:2500, lr:0.01, na lines removed,  eval error: 7.791 > rank Kaggle: 48\n",
    "\n",
    "2017/11/25: improved GruCell, 2 layers, 200 neurons, my_rnn_WIR2_2GruCell_200n_b, batch:2500, lr:0.01, na lines removed,  eval error: 7.836\n",
    "\n",
    "2017/11/25: improved GruCell, 2 layers, 400 neurons, my_rnn_WIR2_2GruCell_400n_b, batch:2500, lr:0.01, na lines removed,  eval error: 7.792\n",
    "\n",
    "2017/11/25: improved SLTM, 2 layers, 200 neurons, my_rnn_WIR2_2LNLSTM_250n_c, batch:2000, lr:0.02, na lines removed,  eval error: 7.788 > rank Kaggle: 35\n",
    "\n",
    "Change of data set: removing values above 730 mm\n",
    "\n",
    "2017/11/25: improved SLTM, 2 layers, 200 neurons, my_rnn_WIR2_2LNLSTM_250n_d, batch:2000, lr:0.02, na lines removed,  eval error: 7.009 > rank Kaggle: 26e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the estimation for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  485477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test = np.load(\"WIR2-X-test-7.npy\")  \n",
    "indices_test = np.load(\"WIR2-indices-test-7.npy\")\n",
    "seq_length_test =  np.load(\"WIR2-seq_length-test-7.npy\")\n",
    "\n",
    "print(\"Number of samples: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To create the submission set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_rnn_WIR2_2LNLSTM_250n_d.ckpt\n",
      "starting at:  0\n",
      "starting at:  53942\n",
      "starting at:  107884\n",
      "starting at:  161826\n",
      "starting at:  215768\n",
      "starting at:  269710\n",
      "starting at:  323652\n",
      "starting at:  377594\n",
      "starting at:  431536\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "batch_size = 10000\n",
    "\n",
    "n_test_samples = 717625\n",
    "train_median_value = 1.0160005\n",
    "\n",
    "results = np.zeros((n_test_samples,2))\n",
    "\n",
    "wrong_indices_test = np.load(\"WIR2-wrong_indices-test-7.npy\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()  \n",
    "    saver.restore(sess, SAVE_FILE)\n",
    "    \n",
    "    for fake_indices in np.array_split(range(len(X_test)), len(X_test) // (batch_size * 5)):\n",
    "        X_batch, seq_length_batch = X_test[fake_indices], seq_length_test[fake_indices]      \n",
    "        estimates = prediction.eval(feed_dict={X: X_batch, seq_length: seq_length_batch, is_training: False})\n",
    "        \n",
    "        print(\"starting at: \", fake_indices[0])\n",
    "        \n",
    "        results[fake_indices,1] = estimates.transpose()\n",
    "        results[fake_indices,0] = indices_test[fake_indices]\n",
    "        results[len(X_test):,1] = train_median_value\n",
    "        results[len(X_test):,0] = wrong_indices_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output = pd.DataFrame(data= results, index= results[:,0], columns=['Id', 'Expected'])\n",
    "output.sort_values(by=['Id'],inplace = True)\n",
    "output.Id = output.Id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.673109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.931320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>4</td>\n",
       "      <td>5.010110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>5</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>6</td>\n",
       "      <td>1.133926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7</td>\n",
       "      <td>2.920722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>8</td>\n",
       "      <td>1.091403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>10</td>\n",
       "      <td>4.587115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.662185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.464071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>13</td>\n",
       "      <td>1.471290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>14</td>\n",
       "      <td>0.790077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>15</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>16</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>17</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>18</td>\n",
       "      <td>0.491401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>19</td>\n",
       "      <td>1.282175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>20</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>21</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>22</td>\n",
       "      <td>1.578264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>23</td>\n",
       "      <td>2.449652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>24</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>25</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>26</td>\n",
       "      <td>0.444226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>27</td>\n",
       "      <td>0.390866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>28</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>29</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>30</td>\n",
       "      <td>4.743181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>71</td>\n",
       "      <td>0.449374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72.0</th>\n",
       "      <td>72</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73.0</th>\n",
       "      <td>73</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.0</th>\n",
       "      <td>74</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75.0</th>\n",
       "      <td>75</td>\n",
       "      <td>0.500442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76.0</th>\n",
       "      <td>76</td>\n",
       "      <td>0.378969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77.0</th>\n",
       "      <td>77</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78.0</th>\n",
       "      <td>78</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79.0</th>\n",
       "      <td>79</td>\n",
       "      <td>0.896850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.0</th>\n",
       "      <td>80</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81.0</th>\n",
       "      <td>81</td>\n",
       "      <td>0.581099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82.0</th>\n",
       "      <td>82</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83.0</th>\n",
       "      <td>83</td>\n",
       "      <td>1.717185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84.0</th>\n",
       "      <td>84</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85.0</th>\n",
       "      <td>85</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86.0</th>\n",
       "      <td>86</td>\n",
       "      <td>0.363960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87.0</th>\n",
       "      <td>87</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88.0</th>\n",
       "      <td>88</td>\n",
       "      <td>0.425606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89.0</th>\n",
       "      <td>89</td>\n",
       "      <td>0.327474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.0</th>\n",
       "      <td>90</td>\n",
       "      <td>0.339689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91.0</th>\n",
       "      <td>91</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92.0</th>\n",
       "      <td>92</td>\n",
       "      <td>0.533094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93.0</th>\n",
       "      <td>93</td>\n",
       "      <td>0.684525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94.0</th>\n",
       "      <td>94</td>\n",
       "      <td>0.872440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95.0</th>\n",
       "      <td>95</td>\n",
       "      <td>0.442852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.0</th>\n",
       "      <td>96</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.0</th>\n",
       "      <td>97</td>\n",
       "      <td>0.448184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98.0</th>\n",
       "      <td>98</td>\n",
       "      <td>0.688181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.0</th>\n",
       "      <td>99</td>\n",
       "      <td>0.785295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Expected\n",
       "1.0      1  0.366489\n",
       "2.0      2  0.673109\n",
       "3.0      3  3.931320\n",
       "4.0      4  5.010110\n",
       "5.0      5  1.016001\n",
       "6.0      6  1.133926\n",
       "7.0      7  2.920722\n",
       "8.0      8  1.091403\n",
       "9.0      9  1.016001\n",
       "10.0    10  4.587115\n",
       "11.0    11  0.662185\n",
       "12.0    12  0.464071\n",
       "13.0    13  1.471290\n",
       "14.0    14  0.790077\n",
       "15.0    15  1.016001\n",
       "16.0    16  1.016001\n",
       "17.0    17  1.016001\n",
       "18.0    18  0.491401\n",
       "19.0    19  1.282175\n",
       "20.0    20  1.016001\n",
       "21.0    21  1.016001\n",
       "22.0    22  1.578264\n",
       "23.0    23  2.449652\n",
       "24.0    24  1.016001\n",
       "25.0    25  1.016001\n",
       "26.0    26  0.444226\n",
       "27.0    27  0.390866\n",
       "28.0    28  1.016001\n",
       "29.0    29  1.016001\n",
       "30.0    30  4.743181\n",
       "...    ...       ...\n",
       "71.0    71  0.449374\n",
       "72.0    72  1.016001\n",
       "73.0    73  1.016001\n",
       "74.0    74  1.016001\n",
       "75.0    75  0.500442\n",
       "76.0    76  0.378969\n",
       "77.0    77  1.016001\n",
       "78.0    78  1.016001\n",
       "79.0    79  0.896850\n",
       "80.0    80  1.016001\n",
       "81.0    81  0.581099\n",
       "82.0    82  1.016001\n",
       "83.0    83  1.717185\n",
       "84.0    84  1.016001\n",
       "85.0    85  1.016001\n",
       "86.0    86  0.363960\n",
       "87.0    87  1.016001\n",
       "88.0    88  0.425606\n",
       "89.0    89  0.327474\n",
       "90.0    90  0.339689\n",
       "91.0    91  1.016001\n",
       "92.0    92  0.533094\n",
       "93.0    93  0.684525\n",
       "94.0    94  0.872440\n",
       "95.0    95  0.442852\n",
       "96.0    96  1.016001\n",
       "97.0    97  0.448184\n",
       "98.0    98  0.688181\n",
       "99.0    99  0.785295\n",
       "100.0  100  1.016001\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile = \"solution_submit_20171125c.csv\"\n",
    "output.to_csv(outfile, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating if the model beats the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_rnn_WIR2_2LNLSTM_250n_d.ckpt\n",
      "Evaluation error: 7.00648677809 Median value error: 7.44104735567\n"
     ]
    }
   ],
   "source": [
    "stupid_pred = np.ones((len(y_eval),1))*np.median(y_eval)\n",
    "eval_errors = np.zeros((len(X_eval),1))\n",
    "predictions = np.zeros((len(X_eval),1))\n",
    "batch_size = 50000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() \n",
    "    saver.restore(sess, \"./my_rnn_WIR2_2LNLSTM_250n_d.ckpt\")\n",
    "    \n",
    "    for indices in np.array_split(range(len(X_eval)), len(X_eval) // batch_size):\n",
    "        X_batch, y_batch,  seq_length_batch = X_eval[indices], y_eval[indices],seq_length_eval[indices]     \n",
    "        eval_errors[indices] = vector_error.eval(feed_dict={X: X_batch, y: y_batch, seq_length: seq_length_batch, is_training: False})\n",
    "        predictions[indices] = prediction.eval(feed_dict={X: X_batch, seq_length: seq_length_batch, is_training: False})\n",
    "    \n",
    "    eval_error = np.mean(eval_errors)\n",
    "    stupid_prediction_error = np.mean(np.abs(stupid_pred - y_eval))\n",
    "    mean_prediction = np.mean(predictions)\n",
    "    \n",
    "    print(\"Evaluation error:\", eval_error, \"Median value error:\", stupid_prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
