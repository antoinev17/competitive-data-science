{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all Files (they must be in data directory in a brother directory of the notebook)\n",
    "data_load = {\n",
    "    'dipole_moments': pd.read_csv('./data/dipole_moments.csv'),\n",
    "    'magnetic_shielding_tensors': pd.read_csv('./data/magnetic_shielding_tensors.csv'),\n",
    "    'mulliken_charges': pd.read_csv('./data/mulliken_charges.csv'),\n",
    "    'potential_energy': pd.read_csv('./data/potential_energy.csv'),\n",
    "    'sample_submission': pd.read_csv('./data/sample_submission.csv'),\n",
    "    'scalar_coupling_contributions': pd.read_csv('./data/scalar_coupling_contributions.csv'),\n",
    "    'structures': pd.read_csv('./data/structures.csv'),\n",
    "    'train': pd.read_csv('./data/train.csv'), \n",
    "    'test': pd.read_csv('./data/test.csv')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>coupling_type_1JHC</th>\n",
       "      <th>coupling_type_1JHN</th>\n",
       "      <th>coupling_type_2JHC</th>\n",
       "      <th>coupling_type_2JHH</th>\n",
       "      <th>coupling_type_2JHN</th>\n",
       "      <th>coupling_type_3JHC</th>\n",
       "      <th>coupling_type_3JHH</th>\n",
       "      <th>coupling_type_3JHN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.2548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-11.2543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  scalar_coupling_constant  \\\n",
       "0   0  dsgdb9nsd_000001             1             0                   84.8076   \n",
       "1   1  dsgdb9nsd_000001             1             2                  -11.2570   \n",
       "2   2  dsgdb9nsd_000001             1             3                  -11.2548   \n",
       "3   3  dsgdb9nsd_000001             1             4                  -11.2543   \n",
       "4   4  dsgdb9nsd_000001             2             0                   84.8074   \n",
       "\n",
       "   coupling_type_1JHC  coupling_type_1JHN  coupling_type_2JHC  \\\n",
       "0                   1                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   1                   0                   0   \n",
       "\n",
       "   coupling_type_2JHH  coupling_type_2JHN  coupling_type_3JHC  \\\n",
       "0                   0                   0                   0   \n",
       "1                   1                   0                   0   \n",
       "2                   1                   0                   0   \n",
       "3                   1                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   coupling_type_3JHH  coupling_type_3JHN  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   0                   0  \n",
       "4                   0                   0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all = data_load['train']\n",
    "MAX_MOL_ATOMS_NB = max(train_all.atom_index_0.max(),train_all.atom_index_1.max()) + 1\n",
    "COUPLING_TYPE_NB = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>atom_C</th>\n",
       "      <th>atom_F</th>\n",
       "      <th>atom_H</th>\n",
       "      <th>atom_N</th>\n",
       "      <th>atom_O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      molecule_name  atom_index         x         y         z  atom_C  atom_F  \\\n",
       "0  dsgdb9nsd_000001           0 -0.012698  1.085804  0.008001       1       0   \n",
       "1  dsgdb9nsd_000001           1  0.002150 -0.006031  0.001976       0       0   \n",
       "2  dsgdb9nsd_000001           2  1.011731  1.463751  0.000277       0       0   \n",
       "3  dsgdb9nsd_000001           3 -0.540815  1.447527 -0.876644       0       0   \n",
       "4  dsgdb9nsd_000001           4 -0.523814  1.437933  0.906397       0       0   \n",
       "\n",
       "   atom_H  atom_N  atom_O  \n",
       "0       0       0       0  \n",
       "1       1       0       0  \n",
       "2       1       0       0  \n",
       "3       1       0       0  \n",
       "4       1       0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirmation with the molecule structure\n",
    "structures = data_load['structures']\n",
    "\n",
    "structures_col = structures.columns\n",
    "\n",
    "\n",
    "# Create one_hot_encoding for the atom type\n",
    "structures = pd.get_dummies(structures, prefix = 'atom', columns = ['atom'])\n",
    "structures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>coupling_type_1JHC</th>\n",
       "      <th>coupling_type_1JHN</th>\n",
       "      <th>coupling_type_2JHC</th>\n",
       "      <th>coupling_type_2JHH</th>\n",
       "      <th>coupling_type_2JHN</th>\n",
       "      <th>coupling_type_3JHC</th>\n",
       "      <th>coupling_type_3JHH</th>\n",
       "      <th>coupling_type_3JHN</th>\n",
       "      <th>DM_X</th>\n",
       "      <th>DM_Y</th>\n",
       "      <th>DM_Z</th>\n",
       "      <th>potential_energy</th>\n",
       "      <th>mulliken_charge_atom_0</th>\n",
       "      <th>mulliken_charge_atom_1</th>\n",
       "      <th>XX_atom_0</th>\n",
       "      <th>YX_atom_0</th>\n",
       "      <th>ZX_atom_0</th>\n",
       "      <th>XY_atom_0</th>\n",
       "      <th>YY_atom_0</th>\n",
       "      <th>ZY_atom_0</th>\n",
       "      <th>XZ_atom_0</th>\n",
       "      <th>YZ_atom_0</th>\n",
       "      <th>ZZ_atom_0</th>\n",
       "      <th>XX_atom_1</th>\n",
       "      <th>YX_atom_1</th>\n",
       "      <th>ZX_atom_1</th>\n",
       "      <th>XY_atom_1</th>\n",
       "      <th>YY_atom_1</th>\n",
       "      <th>ZY_atom_1</th>\n",
       "      <th>XZ_atom_1</th>\n",
       "      <th>YZ_atom_1</th>\n",
       "      <th>ZZ_atom_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.52368</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>31.3410</td>\n",
       "      <td>-1.2317</td>\n",
       "      <td>4.0544</td>\n",
       "      <td>-1.2317</td>\n",
       "      <td>28.9546</td>\n",
       "      <td>-1.7173</td>\n",
       "      <td>4.0546</td>\n",
       "      <td>-1.7173</td>\n",
       "      <td>34.0861</td>\n",
       "      <td>195.3150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>195.3170</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>195.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.52368</td>\n",
       "      <td>0.133922</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>31.5814</td>\n",
       "      <td>1.2173</td>\n",
       "      <td>-4.1474</td>\n",
       "      <td>1.2173</td>\n",
       "      <td>28.9036</td>\n",
       "      <td>-1.6036</td>\n",
       "      <td>-4.1476</td>\n",
       "      <td>-1.6036</td>\n",
       "      <td>33.8967</td>\n",
       "      <td>195.3150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>195.3170</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>195.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8093</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.52368</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>31.5172</td>\n",
       "      <td>4.1086</td>\n",
       "      <td>1.2723</td>\n",
       "      <td>4.1088</td>\n",
       "      <td>33.9068</td>\n",
       "      <td>1.6950</td>\n",
       "      <td>1.2724</td>\n",
       "      <td>1.6951</td>\n",
       "      <td>28.9579</td>\n",
       "      <td>195.3150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>195.3170</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>195.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.52368</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>31.4029</td>\n",
       "      <td>-4.0942</td>\n",
       "      <td>-1.1793</td>\n",
       "      <td>-4.0944</td>\n",
       "      <td>34.0776</td>\n",
       "      <td>1.6259</td>\n",
       "      <td>-1.1795</td>\n",
       "      <td>1.6260</td>\n",
       "      <td>28.9013</td>\n",
       "      <td>195.3150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>195.3170</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>195.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.52368</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>0.133922</td>\n",
       "      <td>31.3410</td>\n",
       "      <td>-1.2317</td>\n",
       "      <td>4.0544</td>\n",
       "      <td>-1.2317</td>\n",
       "      <td>28.9546</td>\n",
       "      <td>-1.7173</td>\n",
       "      <td>4.0546</td>\n",
       "      <td>-1.7173</td>\n",
       "      <td>34.0861</td>\n",
       "      <td>31.5814</td>\n",
       "      <td>1.2173</td>\n",
       "      <td>-4.1474</td>\n",
       "      <td>1.2173</td>\n",
       "      <td>28.9036</td>\n",
       "      <td>-1.6036</td>\n",
       "      <td>-4.1476</td>\n",
       "      <td>-1.6036</td>\n",
       "      <td>33.8967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  scalar_coupling_constant  \\\n",
       "0   0  dsgdb9nsd_000001             1             0                   84.8076   \n",
       "1   4  dsgdb9nsd_000001             2             0                   84.8074   \n",
       "2   7  dsgdb9nsd_000001             3             0                   84.8093   \n",
       "3   9  dsgdb9nsd_000001             4             0                   84.8095   \n",
       "4   1  dsgdb9nsd_000001             1             2                  -11.2570   \n",
       "\n",
       "   coupling_type_1JHC  coupling_type_1JHN  coupling_type_2JHC  \\\n",
       "0                   1                   0                   0   \n",
       "1                   1                   0                   0   \n",
       "2                   1                   0                   0   \n",
       "3                   1                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   coupling_type_2JHH  coupling_type_2JHN  coupling_type_3JHC  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   1                   0                   0   \n",
       "\n",
       "   coupling_type_3JHH  coupling_type_3JHN  DM_X  DM_Y  DM_Z  potential_energy  \\\n",
       "0                   0                   0   0.0   0.0   0.0         -40.52368   \n",
       "1                   0                   0   0.0   0.0   0.0         -40.52368   \n",
       "2                   0                   0   0.0   0.0   0.0         -40.52368   \n",
       "3                   0                   0   0.0   0.0   0.0         -40.52368   \n",
       "4                   0                   0   0.0   0.0   0.0         -40.52368   \n",
       "\n",
       "   mulliken_charge_atom_0  mulliken_charge_atom_1  XX_atom_0  YX_atom_0  \\\n",
       "0                0.133921               -0.535689    31.3410    -1.2317   \n",
       "1                0.133922               -0.535689    31.5814     1.2173   \n",
       "2                0.133923               -0.535689    31.5172     4.1086   \n",
       "3                0.133923               -0.535689    31.4029    -4.0942   \n",
       "4                0.133921                0.133922    31.3410    -1.2317   \n",
       "\n",
       "   ZX_atom_0  XY_atom_0  YY_atom_0  ZY_atom_0  XZ_atom_0  YZ_atom_0  \\\n",
       "0     4.0544    -1.2317    28.9546    -1.7173     4.0546    -1.7173   \n",
       "1    -4.1474     1.2173    28.9036    -1.6036    -4.1476    -1.6036   \n",
       "2     1.2723     4.1088    33.9068     1.6950     1.2724     1.6951   \n",
       "3    -1.1793    -4.0944    34.0776     1.6259    -1.1795     1.6260   \n",
       "4     4.0544    -1.2317    28.9546    -1.7173     4.0546    -1.7173   \n",
       "\n",
       "   ZZ_atom_0  XX_atom_1  YX_atom_1  ZX_atom_1  XY_atom_1  YY_atom_1  \\\n",
       "0    34.0861   195.3150     0.0000    -0.0001     0.0000   195.3170   \n",
       "1    33.8967   195.3150     0.0000    -0.0001     0.0000   195.3170   \n",
       "2    28.9579   195.3150     0.0000    -0.0001     0.0000   195.3170   \n",
       "3    28.9013   195.3150     0.0000    -0.0001     0.0000   195.3170   \n",
       "4    34.0861    31.5814     1.2173    -4.1474     1.2173    28.9036   \n",
       "\n",
       "   ZY_atom_1  XZ_atom_1  YZ_atom_1  ZZ_atom_1  \n",
       "0     0.0007    -0.0001     0.0007   195.3170  \n",
       "1     0.0007    -0.0001     0.0007   195.3170  \n",
       "2     0.0007    -0.0001     0.0007   195.3170  \n",
       "3     0.0007    -0.0001     0.0007   195.3170  \n",
       "4    -1.6036    -4.1476    -1.6036    33.8967  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No shuffle to the samples, this will be done later\n",
    "train_all = data_load['train']\n",
    "train_all =  pd.get_dummies(train_all, prefix = 'coupling_type', columns = ['type'])\n",
    "train_col = train_all.columns\n",
    "\n",
    "# Add the dipole_moments, per molecule\n",
    "dipole_moments = data_load['dipole_moments'].rename(columns = {\"X\": 'DM_X', \"Y\": \"DM_Y\", \"Z\": \"DM_Z\" })\n",
    "train_all = train_all.merge(dipole_moments, on = ['molecule_name'])\n",
    "\n",
    "# Add the potential energy, per molecule\n",
    "potential_energy = data_load['potential_energy']\n",
    "train_all = train_all.merge(potential_energy, on = ['molecule_name'])\n",
    "\n",
    "\n",
    "# Add the Mulliken charges, per atom\n",
    "mulliken_charges = data_load['mulliken_charges']\n",
    "train_all = train_all.merge(mulliken_charges, \n",
    "                            left_on = ['molecule_name', 'atom_index_0'], \n",
    "                            right_on = ['molecule_name', 'atom_index'] )\n",
    "train_all = train_all.merge(mulliken_charges, \n",
    "                            left_on = ['molecule_name', 'atom_index_1'], \n",
    "                            right_on = ['molecule_name', 'atom_index'], suffixes = ('_atom_0', '_atom_1') \n",
    "                           ).drop(['atom_index_atom_0', 'atom_index_atom_1'], axis = 1)\n",
    "\n",
    "# Add magnetic shileding, per atom\n",
    "magnetic_shielding_tensors = data_load['magnetic_shielding_tensors']\n",
    "train_all = train_all.merge(magnetic_shielding_tensors, \n",
    "                            left_on = ['molecule_name', 'atom_index_0'], \n",
    "                            right_on = ['molecule_name', 'atom_index'] )\n",
    "train_all = train_all.merge(magnetic_shielding_tensors, \n",
    "                            left_on = ['molecule_name', 'atom_index_1'], \n",
    "                            right_on = ['molecule_name', 'atom_index'], suffixes = ('_atom_0', '_atom_1') \n",
    "                           ).drop(['atom_index_atom_0', 'atom_index_atom_1'], axis = 1)\n",
    "\n",
    "\n",
    "train_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: besides train features, data are not provided in the test dataset.\n",
    "\n",
    "Should we use those as generative features for the scalar coupling constant?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to prepare the global set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import re\n",
    "\n",
    "def create_coupling_per_mol(molecules, coupled_atoms):\n",
    "\n",
    "    #Transform the input into a dataframe\n",
    "    #molecules = pd.DataFrame(molecules, columns = ['molecule_name', 'atom_index', 'x', 'y', 'z', \n",
    "    #                                               'atom_C', 'atom_F', 'atom_H', 'atom_N', 'atom_O'])\n",
    "    #coupled_atoms = pd.DataFrame(coupled_atoms, columns = ['id', 'molecule_name', 'atom_index_0', 'atom_index_1', \n",
    "    #            'scalar_coupling_constant', 'coupling_type_1JHC', 'coupling_type_1JHN', 'coupling_type_2JHC', \n",
    "    #            'coupling_type_2JHH', 'coupling_type_2JHN', 'coupling_type_3JHC', 'coupling_type_3JHH', 'coupling_type_3JHN'])\n",
    "    \n",
    "    #0 Select all molecules in the batch first (to quicken the operations)\n",
    "    molecules_name = coupled_atoms[['molecule_name']].values.reshape(-1)   \n",
    "    molecules = molecules.loc[molecules['molecule_name'].isin(molecules_name)]\n",
    "\n",
    "    #2 Prepare the features\n",
    "    coupled_atoms.drop(['id'], axis = 1, inplace = True)\n",
    "\n",
    "    coupling_id_col = ['molecule_name', 'atom_index_0', 'atom_index_1' ] \n",
    "    coupling_col = list(filter(re.compile(\"coupling_type.*\").match,coupled_atoms.columns))\n",
    "    outputs_atom_0_col = list(filter(re.compile(\".*_atom_0\").match,coupled_atoms.columns))\n",
    "    outputs_atom_1_col = list(filter(re.compile(\".*_atom_1\").match,coupled_atoms.columns))\n",
    "    outputs_mol_col = ['DM_X','DM_Y','DM_Z','potential_energy']\n",
    "    \n",
    "    #mean_col = ['x_mean', 'y_mean', 'z_mean']\n",
    "    \n",
    "    # Add type and coordinates for each atom_index_0 and atom_index_1\n",
    "    df_tmp = coupled_atoms.merge(molecules, how='inner', \n",
    "                               left_on=['molecule_name', 'atom_index_0'], \n",
    "                               right_on=['molecule_name', 'atom_index'])\n",
    "    df_features_dnn = df_tmp.merge(molecules, how='inner', \n",
    "                                          left_on=['molecule_name', 'atom_index_1'], \n",
    "                                          right_on=['molecule_name', 'atom_index'],\n",
    "                                         suffixes=('_fa0', '_fa1')).drop(['atom_index_fa0','atom_index_fa1' ], axis = 1)\n",
    "    \n",
    "    # Return a tuple with 5 components grouped by molecule, in molecule order\n",
    "    gb = df_features_dnn.groupby(['molecule_name'], sort = True, group_keys = False, as_index = True)\n",
    "    \n",
    "    coupling_pos_col = ['x_fa0' ,'y_fa0','z_fa0', 'x_fa1' ,'y_fa1','z_fa1']\n",
    "    coupling_per_mol = gb.apply(lambda frame: frame[coupling_col + coupling_pos_col].to_numpy()).to_list()\n",
    "    outputs_0 = gb.apply(lambda frame: frame[outputs_atom_0_col + outputs_mol_col].to_numpy()).to_list()\n",
    "    outputs_1 = gb.apply(lambda frame: frame[outputs_atom_1_col + outputs_mol_col].to_numpy()).to_list()\n",
    "    y_per_mol = gb.apply(lambda frame: frame['scalar_coupling_constant'].to_numpy()).to_list()\n",
    "    \n",
    "    # Return the molecule info per molecule, sorted by molecule order\n",
    "    gb = molecules.groupby(['molecule_name'], sort = True, group_keys = False, as_index = True)\n",
    "    molecules_output = gb.apply(lambda frame: frame.drop(['molecule_name', 'atom_index'], axis = 1).to_numpy()).to_list()\n",
    "    \n",
    "    return coupling_per_mol, y_per_mol, outputs_0, outputs_1, molecules_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the global train/eval sets (about 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: \n",
      "for train set: 68002 \n",
      "for eval set: 17001\n",
      "Time for train / eval: 243.0299084369999 / 60.30858497400004\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "validation_ratio = 0.2\n",
    "\n",
    "# Retrieve the full list of molecules in the train/eval set\n",
    "molecule_list = train_all['molecule_name'].unique()\n",
    "\n",
    "# Split the train/eval sets on the molecule list\n",
    "train_mol, eval_mol = np.split(molecule_list, [int((1-validation_ratio)*len(molecule_list))])\n",
    "start = timer()\n",
    "\n",
    "# Select the samples belonging to the molecule train set (WARNING: there is no shuffle there!!)\n",
    "train_molecules = structures[structures['molecule_name'].isin(train_mol)]\n",
    "train_coupling, train_y, train_outputs_0, train_outputs_1, train_mols = create_coupling_per_mol(\n",
    "                                    train_molecules,\n",
    "                                    train_all.loc[train_all['molecule_name'].isin(train_mol)]\n",
    "                                    )\n",
    "# Shuffle the samples by molecule\n",
    "shuffle(train_coupling, train_y, train_outputs_0, outputs_1, train_mols)\n",
    "\n",
    "train_stop = timer()\n",
    "\n",
    "# Select the samples belonging to the molecule eval set (WARNING: there is no shuffle there!!)\n",
    "eval_molecules = structures[structures['molecule_name'].isin(eval_mol)]\n",
    "eval_coupling, eval_y, eval_outputs_0, eval_outputs_1, eval_mols = create_coupling_per_mol(\n",
    "                                    eval_molecules,\n",
    "                                    train_all.loc[train_all['molecule_name'].isin(eval_mol)]\n",
    "                                    )\n",
    "\n",
    "# Shuffle the samples by molecule\n",
    "shuffle(eval_coupling, eval_y, eval_outputs_0, eval_1, eval_mols)\n",
    "\n",
    "stop = timer()\n",
    "\n",
    "print('Number of samples: \\nfor train set:', len(train_coupling), '\\nfor eval set:', len(eval_coupling))\n",
    "print('Time for train / eval:', train_stop-start, '/', stop-train_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To save the global set of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pickle\n",
    "\n",
    "global_data = {\n",
    "    'train_coupling': train_coupling,\n",
    "    'train_y': train_y,\n",
    "    'train_outputs_0': train_outputs_0,\n",
    "    'train_outputs_1': train_outputs_1,\n",
    "    'train_mols': train_mols,\n",
    "    'eval_coupling': eval_coupling,\n",
    "    'eval_y': eval_y,\n",
    "    'eval_outputs_0': eval_outputs_0,\n",
    "    'eval_outputs_1': eval_outputs_1,\n",
    "    'eval_mols': eval_mols,\n",
    "    }\n",
    "\n",
    "# Step 2\n",
    "with open('train-eval-dump-2', 'wb') as dump_file:\n",
    " \n",
    "    # Step 3\n",
    "    pickle.dump(global_data, dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load the global set of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train-eval-dump', 'rb') as dump_file:\n",
    "    global_data = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 20:52:09.635479  6044 deprecation.py:323] From D:\\Program_Files\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ({input_dnn: (2500, 27), input_rnn: (2500, None, 8)}, {labels: (2500,)}), types: ({input_dnn: tf.float32, input_rnn: tf.float32}, {labels: tf.float32})>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative with masking and large batch (2500)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "MASKING_VALUE = 666\n",
    "\n",
    "@tf.function\n",
    "def treat_molecule_set(features, molecules, labels):\n",
    "    \n",
    "    coupled_atoms_set = tf.convert_to_tensor(features)\n",
    "    molecule = tf.convert_to_tensor(molecules)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    \n",
    "    mol_atoms_nb = tf.shape(molecule)[0]\n",
    "    init_molecule = molecule\n",
    "    \n",
    "    # Extend the molecule to 3D and transpose it \n",
    "    molecule = tf.reshape(molecule[:,:3], [-1, 3, 1])\n",
    "    molecule = tf.transpose(molecule, [2, 1, 0])\n",
    "    \n",
    "    # We repeat the molecules and the mean values, so they have the same n_samples * n_atoms dimension\n",
    "    molecule = tf.tile(molecule, [tf.shape(coupled_atoms_set)[0], 1, 1])\n",
    "\n",
    "    mean_3d = tf.reshape(coupled_atoms_set[:, -3:], [-1, 3, 1])  \n",
    "    mean_3d = tf.tile(mean_3d, [1, 1, mol_atoms_nb])\n",
    "    \n",
    "    # We calculate the distance \n",
    "    distance = tf.reduce_sum(tf.square(tf.subtract(molecule, mean_3d)), 1)\n",
    "    \n",
    "    # This function defines for each sample the atoms of the molecule, sorted by decreasing order\n",
    "    ordered_idx = tf.argsort(\n",
    "        distance,\n",
    "        axis=1,\n",
    "        direction='DESCENDING',\n",
    "        stable=False,\n",
    "        name=None\n",
    "    )\n",
    "    \n",
    "    # We apply this sorting order to the initial molecule to calculate, for each couple of atoms, \n",
    "    # the atoms sorted by decreasing distance\n",
    "    sort_mol = tf.gather(\n",
    "        init_molecule,\n",
    "        ordered_idx\n",
    "    )\n",
    "    \n",
    "    # Pad with 666 to keep the same size (is that even needed?)\n",
    "    sort_mol = tf.pad(sort_mol, [[0,0],[0,MAX_MOL_ATOMS_NB-mol_atoms_nb],[0,0]], constant_values=MASKING_VALUE)\n",
    "    \n",
    "    return { 'input_dnn': coupled_atoms_set, \n",
    "          'input_rnn': sort_mol\n",
    "        }, { 'labels': labels }\n",
    "\n",
    "\n",
    "features = global_data['train_set']\n",
    "molecules = global_data['train_mol']\n",
    "labels = global_data['train_labels']\n",
    "\n",
    "def gen_mol():\n",
    "    for i in range(len(features)):     \n",
    "        yield features[i], molecules[i], labels[i] \n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    gen_mol , (tf.float32, tf.float32, tf.float32), \n",
    "    (tf.TensorShape([None, 27]), tf.TensorShape([None,8]), tf.TensorShape([None,]))\n",
    "    )\n",
    "\n",
    "dataset = dataset.flat_map(lambda x, y, z: tf.data.Dataset.from_tensor_slices(treat_molecule_set(x, y, z)))\n",
    "dataset = dataset.batch(2500,\n",
    "    drop_remainder=True)\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.prefetch(1)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ({input_dnn: (2500, 27), input_rnn: (2500, None, 8)}, {labels: (2500,)}), types: ({input_dnn: tf.float32, input_rnn: tf.float32}, {labels: tf.float32})>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative with batch of 1000\n",
    "\n",
    "eval_features = global_data['eval_set']\n",
    "eval_molecules = global_data['eval_mol']\n",
    "eval_labels = global_data['eval_labels']\n",
    "\n",
    "def eval_gen_mol():\n",
    "    for i in range(len(eval_features)):     \n",
    "        yield eval_features[i], eval_molecules[i], eval_labels[i]\n",
    "    \n",
    "eval_dataset = tf.data.Dataset.from_generator(\n",
    "    eval_gen_mol , (tf.float32, tf.float32, tf.float32), \n",
    "    (tf.TensorShape([None, 27]), tf.TensorShape([None,8]), tf.TensorShape([None,]) ))\n",
    "\n",
    "eval_dataset = eval_dataset.flat_map(lambda x, y, z: tf.data.Dataset.from_tensor_slices(treat_molecule_set(x, y, z)))\n",
    "eval_dataset = eval_dataset.batch(2500,\n",
    "    drop_remainder=True)\n",
    "\n",
    "eval_dataset = eval_dataset.repeat()\n",
    "eval_dataset = eval_dataset.prefetch(1)\n",
    "\n",
    "eval_dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 20:52:28.792822  6044 deprecation.py:323] From D:\\Program_Files\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3868: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_dnn (InputLayer)          [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 27)           0           input_dnn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           1792        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_rnn (InputLayer)          [(None, 29, 8)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 29, 8)        0           input_rnn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 29, 32)       5248        masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           8320        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           dropout_2[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1552        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "labels (Dense)                  (None, 1)            17          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,089\n",
      "Trainable params: 21,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "MASKING_VALUE = 666\n",
    "\n",
    "input_dnn = keras.Input(shape =(27 ,), name='input_dnn' )\n",
    "input_rnn = keras.Input(shape = ( MAX_MOL_ATOMS_NB, 8), name = 'input_rnn' )\n",
    "\n",
    "x = layers.Dropout(0.25)(input_dnn)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "y = layers.Masking(mask_value=MASKING_VALUE, input_shape=(MAX_MOL_ATOMS_NB, 8))(input_rnn)\n",
    "y = layers.LSTM(32, return_sequences=True, dropout = 0.25)(y)\n",
    "y = layers.LSTM(32, return_sequences=False, dropout = 0.25)(y)\n",
    "\n",
    "both = layers.concatenate([x, y])\n",
    "both = layers.Dropout(0.5)(both)\n",
    "both = layers.Dense(16, activation='relu')(both)\n",
    "\n",
    "output = layers.Dense(1, activation='linear', name = 'labels')(both)\n",
    "model = keras.Model((input_dnn,input_rnn), output, name = 'model')\n",
    "\n",
    "# Customer score to calculate the competition score\n",
    "\n",
    "def custom_loss_wrapper(input_tensor):\n",
    "    \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        \n",
    "        # Coupling one-hot\n",
    "        c = tf.slice(input_tensor, [0,0], [-1,8])\n",
    "        \n",
    "        # without explicit broadcasting\n",
    "        absolute_error_pred = tf.math.abs(tf.subtract(y_true,y_pred))\n",
    "        absolute_error_per_type = tf.multiply(c, absolute_error_pred)\n",
    "        \n",
    "        zerocount_per_type = tf.math.count_nonzero(absolute_error_per_type, axis = 0)\n",
    "        sum_per_type = tf.math.reduce_sum(absolute_error_per_type, axis = 0) \n",
    "        \n",
    "        zerocount_per_type = tf.boolean_mask(zerocount_per_type, tf.greater(zerocount_per_type,0))\n",
    "        sum_per_type = tf.boolean_mask(sum_per_type, tf.greater(sum_per_type,0.0))\n",
    "        \n",
    "        mean_per_type = sum_per_type / tf.cast(zerocount_per_type, tf.float32)\n",
    "        \n",
    "        mean_per_type = tf.math.log(mean_per_type)\n",
    "        #mean_per_type = tf.boolean_mask(mean_per_type, tf.math.is_finite(mean_per_type))\n",
    "\n",
    "        score = tf.math.reduce_mean(mean_per_type)\n",
    "        \n",
    "        return score\n",
    "    return custom_loss\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights-improvement-201977-10-1.22.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5029\n",
      "Epoch 00001: val_loss improved from inf to 1.31639, saving model to weights-improvement-201978-01-1.32.hdf5\n",
      "100/100 [==============================] - 173s 2s/step - loss: 1.5022 - val_loss: 1.3164\n",
      "Epoch 2/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4463\n",
      "Epoch 00002: val_loss improved from 1.31639 to 1.30549, saving model to weights-improvement-201978-02-1.31.hdf5\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4460 - val_loss: 1.3055\n",
      "Epoch 3/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4770\n",
      "Epoch 00003: val_loss improved from 1.30549 to 1.28907, saving model to weights-improvement-201978-03-1.29.hdf5\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4790 - val_loss: 1.2891\n",
      "Epoch 4/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5927\n",
      "Epoch 00004: val_loss improved from 1.28907 to 1.25070, saving model to weights-improvement-201978-04-1.25.hdf5\n",
      "100/100 [==============================] - 164s 2s/step - loss: 1.5916 - val_loss: 1.2507\n",
      "Epoch 5/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4035\n",
      "Epoch 00005: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4006 - val_loss: 1.3897\n",
      "Epoch 6/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4679\n",
      "Epoch 00006: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4681 - val_loss: 1.2919\n",
      "Epoch 7/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5512\n",
      "Epoch 00007: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.5500 - val_loss: 1.3164\n",
      "Epoch 8/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3973\n",
      "Epoch 00008: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3950 - val_loss: 1.2857\n",
      "Epoch 9/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4013\n",
      "Epoch 00009: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4012 - val_loss: 1.3100\n",
      "Epoch 10/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3596\n",
      "Epoch 00010: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3599 - val_loss: 1.2774\n",
      "Epoch 11/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3727\n",
      "Epoch 00011: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3729 - val_loss: 1.3399\n",
      "Epoch 12/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3665\n",
      "Epoch 00012: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3686 - val_loss: 1.3141\n",
      "Epoch 13/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3361\n",
      "Epoch 00013: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3374 - val_loss: 1.2710\n",
      "Epoch 14/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4096\n",
      "Epoch 00014: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4090 - val_loss: 1.2981\n",
      "Epoch 15/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3731\n",
      "Epoch 00015: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 162s 2s/step - loss: 1.3743 - val_loss: 1.3764\n",
      "Epoch 16/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4850\n",
      "Epoch 00016: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.4846 - val_loss: 1.3094\n",
      "Epoch 17/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4201\n",
      "Epoch 00017: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.4191 - val_loss: 1.3012\n",
      "Epoch 18/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4876\n",
      "Epoch 00018: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.4912 - val_loss: 1.2759\n",
      "Epoch 19/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5598\n",
      "Epoch 00019: val_loss improved from 1.25070 to 1.22877, saving model to weights-improvement-201978-19-1.23.hdf5\n",
      "100/100 [==============================] - 161s 2s/step - loss: 1.5582 - val_loss: 1.2288\n",
      "Epoch 20/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3900\n",
      "Epoch 00020: val_loss did not improve from 1.22877\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.3902 - val_loss: 1.3466\n",
      "Epoch 21/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4549\n",
      "Epoch 00021: val_loss did not improve from 1.22877\n",
      "100/100 [==============================] - 165s 2s/step - loss: 1.4543 - val_loss: 1.2896\n",
      "Epoch 22/25\n",
      " 26/100 [======>.......................] - ETA: 1:49 - loss: 1.5854"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(loss=custom_loss_wrapper(input_dnn), optimizer=adam)\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-\" + str(now.year) + str(now.month) + str(now.day) + \"-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(dataset, epochs=25, validation_data=eval_dataset, \n",
    "                    steps_per_epoch = 100, validation_steps=200, callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions: \n",
    "* how do we bring the dataset to the model with several inputs, and outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submissions are evaluated on the Log of the Mean Absolute Error, calculated for each scalar coupling type, and then averaged across types, so that a 1% decrease in MAE for one type provides the same improvement in score as a 1% decrease for another type.\n",
    "\n",
    "score=1Tt=1Tlog(1nti=1nt|yiyi^|)\n",
    "Where:\n",
    "\n",
    "T is the number of scalar coupling types\n",
    "nt is the number of observations of type t\n",
    "yi is the actual scalar coupling constant for the observation\n",
    "yi^ is the predicted scalar coupling constant for the observation\n",
    "For this metric, the MAE for any group has a floor of 1e-9, so that the minimum (best) possible score for perfect predictions is approximately -20.7232."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dipole_moments.csv - contains the molecular electric dipole moments. These are three dimensional vectors that indicate the charge distribution in the molecule. The first column (molecule_name) are the names of the molecule, the second to fourth column are the X, Y and Z components respectively of the dipole moment.\n",
    "* magnetic_shielding_tensors.csv - contains the magnetic shielding tensors for all atoms in the molecules. The first column (molecule_name) contains the molecule name, the second column (atom_index) contains the index of the atom in the molecule, the  third to eleventh columns contain the XX, YX, ZX, XY, YY, ZY, XZ, YZ and ZZ elements of the tensor/matrix respectively.\n",
    "* mulliken_charges.csv - contains the mulliken charges for all atoms in the molecules. The first column (molecule_name) contains the name of the molecule, the second column (atom_index) contains the index of the atom in the molecule, the third column (mulliken_charge) contains the mulliken charge of the atom.\n",
    "* potential_energy.csv - contains the potential energy of the molecules. The first column (molecule_name) contains the name of the molecule, the second column (potential_energy) contains the potential energy of the molecule.\n",
    "* scalar_coupling_contributions.csv - The scalar coupling constants in train.csv (or corresponding files) are a sum of four terms. scalar_coupling_contributions.csv contain all these terms. The first column (molecule_name) are the name of the molecule, the second (atom_index_0) and third column (atom_index_1) are the atom indices of the atom-pair, the fourth column indicates the type of coupling, the fifth column (fc) is the Fermi Contact contribution, the sixth column (sd) is the Spin-dipolar contribution, the seventh column (pso) is the Paramagnetic spin-orbit contribution and the eighth column (dso) is the Diamagnetic spin-orbit contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set to validate the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ut_coupling = pd.DataFrame({\n",
    "    'molecule_name': ['mol_a', 'mol_b', 'mol_a', 'mol_b', 'mol_b', 'mol_c'],\n",
    "    'atom_index_0':[ 0, 0, 1, 1, 1, 0],\n",
    "    'atom_index_1': [ 1, 1, 2, 2, 3, 1],\n",
    "    'scalar_coupling_constant': [5, 7, 6, 8, 9, 10],\n",
    "    'coupling_type_1JHC':[ 1, 0, 0, 0, 0, 0], \n",
    "    'coupling_type_1JHN':[ 0, 1, 0, 0, 0, 0], \n",
    "    'coupling_type_2JHC':[ 0, 0, 1, 0, 0, 0], \n",
    "    'coupling_type_2JHH':[ 0, 0, 0, 1, 0, 0], \n",
    "    'coupling_type_2JHN':[ 0, 0, 0, 0, 1, 0], \n",
    "    'coupling_type_3JHC':[ 0, 0, 0, 0, 0, 1],\n",
    "    'coupling_type_3JHH':[ 0, 0, 0, 0, 0, 0], \n",
    "    'coupling_type_3JHN':[ 0, 0, 0, 0, 0, 0]\n",
    "})\n",
    "\n",
    "ut_coupling.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_molecules = pd.DataFrame({\n",
    "    'molecule_name': ['mol_a', 'mol_a', 'mol_a', 'mol_b', 'mol_b', 'mol_b', 'mol_b', 'mol_b', 'mol_c', 'mol_c'],\n",
    "    'atom_index':[ 0, 1, 2, 0, 1, 2, 3, 4, 0, 1],\n",
    "    'x': [ -0.5, 0.5, 1, -2, -1, 0, 1, 2, 0.5, 1.5  ],\n",
    "    'y': [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0  ],\n",
    "    'z': [ -0.5, 0.5, 1, -2, -1, 0, 1, 2, 0.5, 1.5  ],\n",
    "    'atom_C': [1,0,0,0,0,1,0,0,0,0],\n",
    "    'atom_F': [0,1,0,0,0,0,1,0,0,0],\n",
    "    'atom_H': [0,0,1,0,0,0,0,1,0,0], \n",
    "    'atom_N': [0,0,0,1,0,0,0,0,1,0],\n",
    "    'atom_O': [0,0,0,0,1,0,0,0,0,1]\n",
    "})\n",
    "\n",
    "ut_molecules.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
