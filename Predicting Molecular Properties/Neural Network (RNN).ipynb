{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all Files (they must be in data directory in a brother directory of the notebook)\n",
    "data_load = {\n",
    "    'dipole_moments': pd.read_csv('./data/magnetic_shielding_tensors.csv'),\n",
    "    'magnetic_shielding_tensors': pd.read_csv('./data/dipole_moments.csv'),\n",
    "    'mulliken_charges': pd.read_csv('./data/mulliken_charges.csv'),\n",
    "    'potential_energy': pd.read_csv('./data/potential_energy.csv'),\n",
    "    'sample_submission': pd.read_csv('./data/sample_submission.csv'),\n",
    "    'scalar_coupling_contributions': pd.read_csv('./data/scalar_coupling_contributions.csv'),\n",
    "    'structures': pd.read_csv('./data/structures.csv'),\n",
    "    'train': pd.read_csv('./data/train.csv'), \n",
    "    'test': pd.read_csv('./data/test.csv')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>coupling_type_1JHC</th>\n",
       "      <th>coupling_type_1JHN</th>\n",
       "      <th>coupling_type_2JHC</th>\n",
       "      <th>coupling_type_2JHH</th>\n",
       "      <th>coupling_type_2JHN</th>\n",
       "      <th>coupling_type_3JHC</th>\n",
       "      <th>coupling_type_3JHH</th>\n",
       "      <th>coupling_type_3JHN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.2548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-11.2543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  scalar_coupling_constant  \\\n",
       "0   0  dsgdb9nsd_000001             1             0                   84.8076   \n",
       "1   1  dsgdb9nsd_000001             1             2                  -11.2570   \n",
       "2   2  dsgdb9nsd_000001             1             3                  -11.2548   \n",
       "3   3  dsgdb9nsd_000001             1             4                  -11.2543   \n",
       "4   4  dsgdb9nsd_000001             2             0                   84.8074   \n",
       "\n",
       "   coupling_type_1JHC  coupling_type_1JHN  coupling_type_2JHC  \\\n",
       "0                   1                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   1                   0                   0   \n",
       "\n",
       "   coupling_type_2JHH  coupling_type_2JHN  coupling_type_3JHC  \\\n",
       "0                   0                   0                   0   \n",
       "1                   1                   0                   0   \n",
       "2                   1                   0                   0   \n",
       "3                   1                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   coupling_type_3JHH  coupling_type_3JHN  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   0                   0  \n",
       "4                   0                   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all = data_load['train']\n",
    "MAX_MOL_ATOMS_NB = max(train_all.atom_index_0.max(),train_all.atom_index_1.max()) + 1\n",
    "\n",
    "# No shuffle to the samples, this will be done later\n",
    "\n",
    "train_all =  pd.get_dummies(train_all, prefix = 'coupling_type', columns = ['type'])\n",
    "train_col = train_all.columns\n",
    "\n",
    "COUPLING_TYPE_NB = 8\n",
    "\n",
    "train_all.head()\n",
    "# we have a molecule of methane\n",
    "# strangely, scalar coupling between identical atoms (we should have a symetric molecule) are slightly different (7 per 100,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>atom_C</th>\n",
       "      <th>atom_F</th>\n",
       "      <th>atom_H</th>\n",
       "      <th>atom_N</th>\n",
       "      <th>atom_O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      molecule_name  atom_index         x         y         z  atom_C  atom_F  \\\n",
       "0  dsgdb9nsd_000001           0 -0.012698  1.085804  0.008001       1       0   \n",
       "1  dsgdb9nsd_000001           1  0.002150 -0.006031  0.001976       0       0   \n",
       "2  dsgdb9nsd_000001           2  1.011731  1.463751  0.000277       0       0   \n",
       "3  dsgdb9nsd_000001           3 -0.540815  1.447527 -0.876644       0       0   \n",
       "4  dsgdb9nsd_000001           4 -0.523814  1.437933  0.906397       0       0   \n",
       "\n",
       "   atom_H  atom_N  atom_O  \n",
       "0       0       0       0  \n",
       "1       1       0       0  \n",
       "2       1       0       0  \n",
       "3       1       0       0  \n",
       "4       1       0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirmation with the molecule structure\n",
    "structures = data_load['structures']\n",
    "\n",
    "structures_col = structures.columns\n",
    "\n",
    "\n",
    "# Create one_hot_encoding for the atom type\n",
    "structures = pd.get_dummies(structures, prefix = 'atom', columns = ['atom'])\n",
    "structures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: besides train features, data are not provided in the test dataset.\n",
    "\n",
    "Should we use those as generative features for the scalar coupling constant?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "* We try to test the following idea: we will train the model with as an input:\n",
    " - the couple of atoms nature and positions\n",
    " - the position of all other atoms in the molecule, by decreasing distance from the barycentre of the 2 considered atoms\n",
    "and as ouputs, the J value but also the other properties that are provided\n",
    "* Create for each sample, ie each couple of atoms for which a coupling constant is provided, the 1D features for standard RNN and the series of molecules atoms positions for the RNN part of the model\n",
    "* Prepare the additional output, to improve training\n",
    "\n",
    "For performance improvement, the idea is to create the atoms position in the molecule during the mini-batch creation, not in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a 2D matrix representing all atoms position for a particular molecule\n",
    "The function should order the atoms in decreasing distance from the A-B atoms considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: should we keep the atoms of the coupling in the list of atoms of the molecule ?\n",
    "I think we do, because we want this list of atoms to predict the global variables of molecule, independently of the coupling prediction\n",
    "\n",
    "#### Question 2: for J1 coupling, in which order should we return the coupled molecules (as we order based on the center, the order will be arbitrary - based on rounding error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train and evaluation sets, at molecule level (it is how the test set is built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to prepare the global set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def create_coupling_per_mol(molecules, coupled_atoms):\n",
    "\n",
    "    #Transform the input into a dataframe\n",
    "    molecules = pd.DataFrame(molecules, columns = ['molecule_name', 'atom_index', 'x', 'y', 'z', 'atom_C', 'atom_F', 'atom_H', 'atom_N', 'atom_O'])\n",
    "    coupled_atoms = pd.DataFrame(coupled_atoms, columns = ['id', 'molecule_name', 'atom_index_0', 'atom_index_1', \n",
    "                'scalar_coupling_constant', 'coupling_type_1JHC', 'coupling_type_1JHN', 'coupling_type_2JHC', \n",
    "                'coupling_type_2JHH', 'coupling_type_2JHN', 'coupling_type_3JHC', 'coupling_type_3JHH', 'coupling_type_3JHN'])\n",
    "    \n",
    "    #0 Select all molecules in the batch first (to quicken the operations)\n",
    "    molecules_name = coupled_atoms[['molecule_name']].values.reshape(-1)   \n",
    "    molecules = molecules.loc[molecules['molecule_name'].isin(molecules_name)]\n",
    "\n",
    "    #2 Prepare the features\n",
    "    coupled_atoms.drop(['id'], axis = 1, inplace = True)\n",
    "\n",
    "    coupling_id_col = ['molecule_name', 'atom_index_0', 'atom_index_1' ] \n",
    "    mean_col = ['x_mean', 'y_mean', 'z_mean']\n",
    "\n",
    "    df_tmp = coupled_atoms.merge(molecules, how='inner', \n",
    "                               left_on=['molecule_name', 'atom_index_0'], \n",
    "                               right_on=['molecule_name', 'atom_index'])\n",
    "    df_features_dnn = df_tmp.merge(molecules, how='inner', \n",
    "                                          left_on=['molecule_name', 'atom_index_1'], \n",
    "                                          right_on=['molecule_name', 'atom_index'],\n",
    "                                         suffixes=('_a0', '_a1')).drop(['atom_index_a0','atom_index_a1' ], axis = 1)\n",
    " \n",
    "    df_features_dnn['x_mean'] = df_features_dnn[['x_a0','x_a1']].mean(axis = 1)\n",
    "    df_features_dnn['y_mean'] = df_features_dnn[['y_a0','y_a1']].mean(axis = 1)\n",
    "    df_features_dnn['z_mean'] = df_features_dnn[['z_a0','z_a1']].mean(axis = 1)\n",
    "    \n",
    "    # Return a tuple features, labels for each molecule, sorted by molecule order\n",
    "    gb = df_features_dnn.groupby(['molecule_name'], sort = True, group_keys = False, as_index = True)\n",
    "            \n",
    "    features_per_mol = gb.apply(lambda frame: frame.drop(['scalar_coupling_constant']+coupling_id_col, \n",
    "                                                         axis = 1).to_numpy()).to_list()\n",
    "    labels_per_mol = gb.apply(lambda frame: frame['scalar_coupling_constant'].to_numpy()).to_list()\n",
    "    \n",
    "    # Return the molecule info per molecule, sorted by molecule order\n",
    "    gb = molecules.groupby(['molecule_name'], sort = True, group_keys = False, as_index = True)\n",
    "    molecules_output = gb.apply(lambda frame: frame.drop(['molecule_name', 'atom_index'], axis = 1).to_numpy()).to_list()\n",
    "    \n",
    "    return features_per_mol, labels_per_mol, molecules_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the global train/eval sets (about 3 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "validation_ratio = 0.2\n",
    "\n",
    "# Retrieve the full list of molecules in the train/eval set\n",
    "molecule_list = train_all['molecule_name'].unique()\n",
    "\n",
    "# Split the train/eval sets on the molecule list\n",
    "train_mol, eval_mol = np.split(molecule_list, [int((1-validation_ratio)*len(molecule_list))])\n",
    "start = timer()\n",
    "\n",
    "# Select the samples belonging to the molecule train set (WARNING: there is no shuffle there!!)\n",
    "train_molecules = structures[structures['molecule_name'].isin(train_mol)]\n",
    "train_set, train_labels, train_mols = create_coupling_per_mol(train_molecules,\n",
    "                                    train_all.loc[train_all['molecule_name'].isin(train_mol)]\n",
    "                                    )\n",
    "# Shuffle the samples by molecule\n",
    "shuffle(train_set, train_labels, train_mols)\n",
    "\n",
    "train_stop = timer()\n",
    "\n",
    "# Select the samples belonging to the molecule eval set (WARNING: there is no shuffle there!!)\n",
    "eval_molecules = structures[structures['molecule_name'].isin(eval_mol)]\n",
    "eval_set, eval_labels, eval_mols = create_coupling_per_mol(eval_molecules,\n",
    "                                    train_all.loc[train_all['molecule_name'].isin(eval_mol)]\n",
    "                                    )\n",
    "\n",
    "# Shuffle the samples by molecule\n",
    "shuffle(eval_set, eval_labels, eval_mols )\n",
    "\n",
    "stop = timer()\n",
    "\n",
    "print('Number of samples: \\nfor train set:', len(train_set), '\\nfor eval set:', len(eval_set))\n",
    "print('Time for train / eval:', train_stop-start, '/', stop-train_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To save the global set of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pickle\n",
    "\n",
    "global_data = {\n",
    "    'train_set': train_set,\n",
    "    'train_labels': train_labels,\n",
    "    'train_mol': train_mols,\n",
    "    'eval_set': eval_set,\n",
    "    'eval_labels': eval_labels,\n",
    "    'eval_mol': eval_mols\n",
    "    }\n",
    "\n",
    "# Step 2\n",
    "with open('train-eval-dump', 'wb') as dump_file:\n",
    " \n",
    "  # Step 3\n",
    "  pickle.dump(global_data, dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load the global set of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train-eval-dump', 'rb') as dump_file:\n",
    "    global_data = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 20:52:09.635479  6044 deprecation.py:323] From D:\\Program_Files\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ({input_dnn: (2500, 27), input_rnn: (2500, None, 8)}, {labels: (2500,)}), types: ({input_dnn: tf.float32, input_rnn: tf.float32}, {labels: tf.float32})>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative with masking and large batch (2500)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "MASKING_VALUE = 666\n",
    "\n",
    "@tf.function\n",
    "def treat_molecule_set(features, molecules, labels):\n",
    "    \n",
    "    coupled_atoms_set = tf.convert_to_tensor(features)\n",
    "    molecule = tf.convert_to_tensor(molecules)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    \n",
    "    mol_atoms_nb = tf.shape(molecule)[0]\n",
    "    init_molecule = molecule\n",
    "    \n",
    "    # Extend the molecule to 3D and transpose it \n",
    "    molecule = tf.reshape(molecule[:,:3], [-1, 3, 1])\n",
    "    molecule = tf.transpose(molecule, [2, 1, 0])\n",
    "    \n",
    "    # We repeat the molecules and the mean values, so they have the same n_samples * n_atoms dimension\n",
    "    molecule = tf.tile(molecule, [tf.shape(coupled_atoms_set)[0], 1, 1])\n",
    "\n",
    "    mean_3d = tf.reshape(coupled_atoms_set[:, -3:], [-1, 3, 1])  \n",
    "    mean_3d = tf.tile(mean_3d, [1, 1, mol_atoms_nb])\n",
    "    \n",
    "    # We calculate the distance \n",
    "    distance = tf.reduce_sum(tf.square(tf.subtract(molecule, mean_3d)), 1)\n",
    "    \n",
    "    # This function defines for each sample the atoms of the molecule, sorted by decreasing order\n",
    "    ordered_idx = tf.argsort(\n",
    "        distance,\n",
    "        axis=1,\n",
    "        direction='DESCENDING',\n",
    "        stable=False,\n",
    "        name=None\n",
    "    )\n",
    "    \n",
    "    # We apply this sorting order to the initial molecule to calculate, for each couple of atoms, \n",
    "    # the atoms sorted by decreasing distance\n",
    "    sort_mol = tf.gather(\n",
    "        init_molecule,\n",
    "        ordered_idx\n",
    "    )\n",
    "    \n",
    "    # Pad with 666 to keep the same size (is that even needed?)\n",
    "    sort_mol = tf.pad(sort_mol, [[0,0],[0,MAX_MOL_ATOMS_NB-mol_atoms_nb],[0,0]], constant_values=MASKING_VALUE)\n",
    "    \n",
    "    return { 'input_dnn': coupled_atoms_set, \n",
    "          'input_rnn': sort_mol\n",
    "        }, { 'labels': labels }\n",
    "\n",
    "\n",
    "features = global_data['train_set']\n",
    "molecules = global_data['train_mol']\n",
    "labels = global_data['train_labels']\n",
    "\n",
    "def gen_mol():\n",
    "    for i in range(len(features)):     \n",
    "        yield features[i], molecules[i], labels[i] \n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    gen_mol , (tf.float32, tf.float32, tf.float32), \n",
    "    (tf.TensorShape([None, 27]), tf.TensorShape([None,8]), tf.TensorShape([None,]))\n",
    "    )\n",
    "\n",
    "dataset = dataset.flat_map(lambda x, y, z: tf.data.Dataset.from_tensor_slices(treat_molecule_set(x, y, z)))\n",
    "dataset = dataset.batch(2500,\n",
    "    drop_remainder=True)\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.prefetch(1)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ({input_dnn: (2500, 27), input_rnn: (2500, None, 8)}, {labels: (2500,)}), types: ({input_dnn: tf.float32, input_rnn: tf.float32}, {labels: tf.float32})>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative with batch of 1000\n",
    "\n",
    "eval_features = global_data['eval_set']\n",
    "eval_molecules = global_data['eval_mol']\n",
    "eval_labels = global_data['eval_labels']\n",
    "\n",
    "def eval_gen_mol():\n",
    "    for i in range(len(eval_features)):     \n",
    "        yield eval_features[i], eval_molecules[i], eval_labels[i]\n",
    "    \n",
    "eval_dataset = tf.data.Dataset.from_generator(\n",
    "    eval_gen_mol , (tf.float32, tf.float32, tf.float32), \n",
    "    (tf.TensorShape([None, 27]), tf.TensorShape([None,8]), tf.TensorShape([None,]) ))\n",
    "\n",
    "eval_dataset = eval_dataset.flat_map(lambda x, y, z: tf.data.Dataset.from_tensor_slices(treat_molecule_set(x, y, z)))\n",
    "eval_dataset = eval_dataset.batch(2500,\n",
    "    drop_remainder=True)\n",
    "\n",
    "eval_dataset = eval_dataset.repeat()\n",
    "eval_dataset = eval_dataset.prefetch(1)\n",
    "\n",
    "eval_dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 20:52:28.792822  6044 deprecation.py:323] From D:\\Program_Files\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3868: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_dnn (InputLayer)          [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 27)           0           input_dnn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           1792        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_rnn (InputLayer)          [(None, 29, 8)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 29, 8)        0           input_rnn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 29, 32)       5248        masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           8320        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           dropout_2[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1552        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "labels (Dense)                  (None, 1)            17          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,089\n",
      "Trainable params: 21,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "MASKING_VALUE = 666\n",
    "\n",
    "input_dnn = keras.Input(shape =(27 ,), name='input_dnn' )\n",
    "input_rnn = keras.Input(shape = ( MAX_MOL_ATOMS_NB, 8), name = 'input_rnn' )\n",
    "\n",
    "x = layers.Dropout(0.25)(input_dnn)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "y = layers.Masking(mask_value=MASKING_VALUE, input_shape=(MAX_MOL_ATOMS_NB, 8))(input_rnn)\n",
    "y = layers.LSTM(32, return_sequences=True, dropout = 0.25)(y)\n",
    "y = layers.LSTM(32, return_sequences=False, dropout = 0.25)(y)\n",
    "\n",
    "both = layers.concatenate([x, y])\n",
    "both = layers.Dropout(0.5)(both)\n",
    "both = layers.Dense(16, activation='relu')(both)\n",
    "\n",
    "output = layers.Dense(1, activation='linear', name = 'labels')(both)\n",
    "model = keras.Model((input_dnn,input_rnn), output, name = 'model')\n",
    "\n",
    "# Customer score to calculate the competition score\n",
    "\n",
    "def custom_loss_wrapper(input_tensor):\n",
    "    \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        \n",
    "        # Coupling one-hot\n",
    "        c = tf.slice(input_tensor, [0,0], [-1,8])\n",
    "        \n",
    "        # without explicit broadcasting\n",
    "        absolute_error_pred = tf.math.abs(tf.subtract(y_true,y_pred))\n",
    "        absolute_error_per_type = tf.multiply(c, absolute_error_pred)\n",
    "        \n",
    "        zerocount_per_type = tf.math.count_nonzero(absolute_error_per_type, axis = 0)\n",
    "        sum_per_type = tf.math.reduce_sum(absolute_error_per_type, axis = 0) \n",
    "        \n",
    "        zerocount_per_type = tf.boolean_mask(zerocount_per_type, tf.greater(zerocount_per_type,0))\n",
    "        sum_per_type = tf.boolean_mask(sum_per_type, tf.greater(sum_per_type,0.0))\n",
    "        \n",
    "        mean_per_type = sum_per_type / tf.cast(zerocount_per_type, tf.float32)\n",
    "        \n",
    "        mean_per_type = tf.math.log(mean_per_type)\n",
    "        #mean_per_type = tf.boolean_mask(mean_per_type, tf.math.is_finite(mean_per_type))\n",
    "\n",
    "        score = tf.math.reduce_mean(mean_per_type)\n",
    "        \n",
    "        return score\n",
    "    return custom_loss\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights-improvement-201977-10-1.22.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5029\n",
      "Epoch 00001: val_loss improved from inf to 1.31639, saving model to weights-improvement-201978-01-1.32.hdf5\n",
      "100/100 [==============================] - 173s 2s/step - loss: 1.5022 - val_loss: 1.3164\n",
      "Epoch 2/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4463\n",
      "Epoch 00002: val_loss improved from 1.31639 to 1.30549, saving model to weights-improvement-201978-02-1.31.hdf5\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4460 - val_loss: 1.3055\n",
      "Epoch 3/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4770\n",
      "Epoch 00003: val_loss improved from 1.30549 to 1.28907, saving model to weights-improvement-201978-03-1.29.hdf5\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4790 - val_loss: 1.2891\n",
      "Epoch 4/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5927\n",
      "Epoch 00004: val_loss improved from 1.28907 to 1.25070, saving model to weights-improvement-201978-04-1.25.hdf5\n",
      "100/100 [==============================] - 164s 2s/step - loss: 1.5916 - val_loss: 1.2507\n",
      "Epoch 5/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4035\n",
      "Epoch 00005: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4006 - val_loss: 1.3897\n",
      "Epoch 6/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4679\n",
      "Epoch 00006: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4681 - val_loss: 1.2919\n",
      "Epoch 7/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5512\n",
      "Epoch 00007: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.5500 - val_loss: 1.3164\n",
      "Epoch 8/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3973\n",
      "Epoch 00008: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3950 - val_loss: 1.2857\n",
      "Epoch 9/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4013\n",
      "Epoch 00009: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4012 - val_loss: 1.3100\n",
      "Epoch 10/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3596\n",
      "Epoch 00010: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3599 - val_loss: 1.2774\n",
      "Epoch 11/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3727\n",
      "Epoch 00011: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3729 - val_loss: 1.3399\n",
      "Epoch 12/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3665\n",
      "Epoch 00012: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3686 - val_loss: 1.3141\n",
      "Epoch 13/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3361\n",
      "Epoch 00013: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.3374 - val_loss: 1.2710\n",
      "Epoch 14/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4096\n",
      "Epoch 00014: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 163s 2s/step - loss: 1.4090 - val_loss: 1.2981\n",
      "Epoch 15/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3731\n",
      "Epoch 00015: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 162s 2s/step - loss: 1.3743 - val_loss: 1.3764\n",
      "Epoch 16/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4850\n",
      "Epoch 00016: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.4846 - val_loss: 1.3094\n",
      "Epoch 17/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4201\n",
      "Epoch 00017: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.4191 - val_loss: 1.3012\n",
      "Epoch 18/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4876\n",
      "Epoch 00018: val_loss did not improve from 1.25070\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.4912 - val_loss: 1.2759\n",
      "Epoch 19/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.5598\n",
      "Epoch 00019: val_loss improved from 1.25070 to 1.22877, saving model to weights-improvement-201978-19-1.23.hdf5\n",
      "100/100 [==============================] - 161s 2s/step - loss: 1.5582 - val_loss: 1.2288\n",
      "Epoch 20/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.3900\n",
      "Epoch 00020: val_loss did not improve from 1.22877\n",
      "100/100 [==============================] - 160s 2s/step - loss: 1.3902 - val_loss: 1.3466\n",
      "Epoch 21/25\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1.4549\n",
      "Epoch 00021: val_loss did not improve from 1.22877\n",
      "100/100 [==============================] - 165s 2s/step - loss: 1.4543 - val_loss: 1.2896\n",
      "Epoch 22/25\n",
      " 26/100 [======>.......................] - ETA: 1:49 - loss: 1.5854"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(loss=custom_loss_wrapper(input_dnn), optimizer=adam)\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-\" + str(now.year) + str(now.month) + str(now.day) + \"-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(dataset, epochs=25, validation_data=eval_dataset, \n",
    "                    steps_per_epoch = 100, validation_steps=200, callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions: \n",
    "* how do we bring the dataset to the model with several inputs, and outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submissions are evaluated on the Log of the Mean Absolute Error, calculated for each scalar coupling type, and then averaged across types, so that a 1% decrease in MAE for one type provides the same improvement in score as a 1% decrease for another type.\n",
    "\n",
    "score=1T∑t=1Tlog(1nt∑i=1nt|yi−yi^|)\n",
    "Where:\n",
    "\n",
    "T is the number of scalar coupling types\n",
    "nt is the number of observations of type t\n",
    "yi is the actual scalar coupling constant for the observation\n",
    "yi^ is the predicted scalar coupling constant for the observation\n",
    "For this metric, the MAE for any group has a floor of 1e-9, so that the minimum (best) possible score for perfect predictions is approximately -20.7232."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dipole_moments.csv - contains the molecular electric dipole moments. These are three dimensional vectors that indicate the charge distribution in the molecule. The first column (molecule_name) are the names of the molecule, the second to fourth column are the X, Y and Z components respectively of the dipole moment.\n",
    "* magnetic_shielding_tensors.csv - contains the magnetic shielding tensors for all atoms in the molecules. The first column (molecule_name) contains the molecule name, the second column (atom_index) contains the index of the atom in the molecule, the  third to eleventh columns contain the XX, YX, ZX, XY, YY, ZY, XZ, YZ and ZZ elements of the tensor/matrix respectively.\n",
    "* mulliken_charges.csv - contains the mulliken charges for all atoms in the molecules. The first column (molecule_name) contains the name of the molecule, the second column (atom_index) contains the index of the atom in the molecule, the third column (mulliken_charge) contains the mulliken charge of the atom.\n",
    "* potential_energy.csv - contains the potential energy of the molecules. The first column (molecule_name) contains the name of the molecule, the second column (potential_energy) contains the potential energy of the molecule.\n",
    "* scalar_coupling_contributions.csv - The scalar coupling constants in train.csv (or corresponding files) are a sum of four terms. scalar_coupling_contributions.csv contain all these terms. The first column (molecule_name) are the name of the molecule, the second (atom_index_0) and third column (atom_index_1) are the atom indices of the atom-pair, the fourth column indicates the type of coupling, the fifth column (fc) is the Fermi Contact contribution, the sixth column (sd) is the Spin-dipolar contribution, the seventh column (pso) is the Paramagnetic spin-orbit contribution and the eighth column (dso) is the Diamagnetic spin-orbit contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set to validate the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ut_coupling = pd.DataFrame({\n",
    "    'molecule_name': ['mol_a', 'mol_b', 'mol_a', 'mol_b', 'mol_b', 'mol_c'],\n",
    "    'atom_index_0':[ 0, 0, 1, 1, 1, 0],\n",
    "    'atom_index_1': [ 1, 1, 2, 2, 3, 1],\n",
    "    'scalar_coupling_constant': [5, 7, 6, 8, 9, 10],\n",
    "    'coupling_type_1JHC':[ 1, 0, 0, 0, 0, 0], \n",
    "    'coupling_type_1JHN':[ 0, 1, 0, 0, 0, 0], \n",
    "    'coupling_type_2JHC':[ 0, 0, 1, 0, 0, 0], \n",
    "    'coupling_type_2JHH':[ 0, 0, 0, 1, 0, 0], \n",
    "    'coupling_type_2JHN':[ 0, 0, 0, 0, 1, 0], \n",
    "    'coupling_type_3JHC':[ 0, 0, 0, 0, 0, 1],\n",
    "    'coupling_type_3JHH':[ 0, 0, 0, 0, 0, 0], \n",
    "    'coupling_type_3JHN':[ 0, 0, 0, 0, 0, 0]\n",
    "})\n",
    "\n",
    "ut_coupling.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_molecules = pd.DataFrame({\n",
    "    'molecule_name': ['mol_a', 'mol_a', 'mol_a', 'mol_b', 'mol_b', 'mol_b', 'mol_b', 'mol_b', 'mol_c', 'mol_c'],\n",
    "    'atom_index':[ 0, 1, 2, 0, 1, 2, 3, 4, 0, 1],\n",
    "    'x': [ -0.5, 0.5, 1, -2, -1, 0, 1, 2, 0.5, 1.5  ],\n",
    "    'y': [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0  ],\n",
    "    'z': [ -0.5, 0.5, 1, -2, -1, 0, 1, 2, 0.5, 1.5  ],\n",
    "    'atom_C': [1,0,0,0,0,1,0,0,0,0],\n",
    "    'atom_F': [0,1,0,0,0,0,1,0,0,0],\n",
    "    'atom_H': [0,0,1,0,0,0,0,1,0,0], \n",
    "    'atom_N': [0,0,0,1,0,0,0,0,1,0],\n",
    "    'atom_O': [0,0,0,0,1,0,0,0,0,1]\n",
    "})\n",
    "\n",
    "ut_molecules.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
